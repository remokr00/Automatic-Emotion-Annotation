# -*- coding: utf-8 -*-
"""Annotazione_di_Emozioni_e_Tratti_Morali_su_notizie_dell'HuffPost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a5canaufoaURb7hnCOU6OXTQ9sGBGqdD

# **Annotazione di Emozioni e Tratti Morali su notizie dell'HuffPost attraverso Large Language Model**

# **Table of Contents**

- **Introduzione**
- **Related Works**
- **1. Recupero e Analisi Dataset**
  - 1.1 Analisi Dataset
- **2. Meta Llama 3.1**
  - 2.1 Meta Llama 3.1 result analysis
    - 2.1.1 Statistiche dei risultati di Llama 3.1
    - 2.1.2 Analisi della Correlazione
    - 2.1.3 Qul è il rapporto tra le emozioni neutrali e le emozioni esplicite?
    - 2.1.4 Emotions Distributions
    - 2.1.5 Entropia
    - 2.1.6 Confronto Emozioni positive e negative
  - 2.2 Conclusioni per Llama 3.1
- **3. Mistral**
  - 3.1 Mistral result analysis
    - 3.1.1 Statistiche dei risultati di Mistral
    - 3.1.2 Analisi della Correlazione
    - 3.1.3 Qul è il rapporto tra le emozioni neutrali e le emozioni esplicite?
    - 3.1.4 Emotions Distributions
    - 3.1.5 Entropia
    - 3.1.6 Confronto Emozioni positive e negative
  - 3.2 Conclusioni per Mistral
- **4. Gemma**
  - 4.1 Gemma result analysis
    - 4.1.1 Statistiche dei risultati di Gemma
    - 4.1.2 Analisi della Correlazione
    - 4.1.3 Qul è il rapporto tra le emozioni neutrali e le emozioni esplicite?
    - 4.1.4 Emotions Distributions
    - 4.1.5 Entropia
    - 4.1.6 Confronto Emozioni positive e negative
  - 4.2 Conclusioni per Gemma
- **5. Confronto Risultati dei modelli**
- **6. Confronto tra modelli (K-statistics)**
  - 6.1 Calcolo K-statistics fra LLama e Mistral
  - 6.2 Calcolo K-statistics fra LLama e Gemma
  - 6.3 Calcolo K-statistics fra Mistral e Gemma
  - 6.4 Confronto tra tutti i modelli
- **7. Confronto della *detection* tra modelli (K-statistics)**
  - 7.1 Calcolo K-statistics per la detection fra LLama e Mistral
  - 7.2 Calcolo K-statistics per la detection fra LLama e Gemma
  - 7.3 Calcolo K-statistics per la detection fra Mistral e Gemma
  - 7.4 Confronto tra tutti i modelli
- **Conclusioni**

- **Appendice A**

# **Introduzione**

Nei media, in particolare nelle notizie, le emozioni e i valori morali svolgono un ruolo cruciale nel modellare l'opinione pubblica e nel determinare il coinvolgimento del pubblico.
Il progetto si propone di annotare e analizzare emozioni e tratti morali presenti nei contenuti pubblicati dall'HuffPost utilizzando modelli di linguaggio avanzato:
- LLama 3.1
- Mistral
- Gemma

Gli obiettivi sono verificare la capacità dei diversi modelli nell'annotazione delle emozioni, valutarne la coerenza e il grado di accordo che questi hanno tra di loro. Ciò risulta essere fondamentale poiché con l'aumento dei dati a disposizione e il costo dell'impiego umano per l'annotazione di dataset, risulta essere di estrema importanza avere a disposizione una metodologia automatica di annotazione che sia affidabile.

La metodologia utilizzata per l'annotazione del dataset preso in considerazione consiste nel fornire ai modelli due prompt distinti: il primo relativo alla valutazione delle emozioni all'interno del testo; il secondo utilizzato invece per l'annotazione delle dimensioni morali. Per ogni modello sono state esplorate tre diverse modalità di decoding: *greedy decoding*, *top-k sampling*, *top-p sampling*. I modelli, inoltre hanno annotato le emozioni in due scenari differenti: in un caso veniva data possibillità al modello di considera una "emozione" (o tratto morale) neutrale, nel secondo è stata preclusa questa possibilità.

Questo approccio, ispirato dal lavoro [E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases](https://arxiv.org/abs/2409.09001) consente non solo di analizzare le capacità di modelli linguistici avanzati, ma anche di identificare strategie ottimali per un'annotazione automatica che sia robusta, coerente e scalabile. I risultati di questo studio offriranno un confronto dettagliato tra i modelli selezionati aggiungendo un punto di vista diverso dai lavori effettuati nello stesso ambito.

**NOTA**: I *template* dei prompt utilizzati per i diversi modelli sono specificati nell'Appendice A. Oltre ai prompt, è presente una breve spiegazione del perché questi, a seconda del modello, risultano essere più efficaci.

# **Related Works**

Nell'ambito dell'annotazione automatica di emozioni e tratti morali, diversi studi hanno contribuito a definire metodi e tecnologie che utilizzano *language model* avanzati per analizzare e interpretare il linguaggio naturale.

Nell'articolo "E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases" (et al. Greco C. M.) sono stati sfruttati dei *language model* specializzati nel riconoscimento di emozioni per creare un dataset in grado di collegare a articoli di cronaca emozioni, tratti morali e eventi. Tutto ciò per verificare come i *bias* creati dai media possano influenzare la percezione dei lettori per quanto concerne i casi legali **[1]**.

Un lavoro simile è stato svolto da (et al. Lei Y.) in cui viene presentano EMONA, un nuovo dataset contenente annotazioni relative a giudizi morali a livello di evento. Gli autori sottolineano come il riconoscimento della moralità degli eventi sia una sfida significativa, dato che i giudizi morali sono spesso impliciti. L'analisi e i risultati sperimentali mostrano che i giudizi morali degli eventi rappresentano un'informazione rilevante per la comprensione del bias ideologico e della soggettività degli articoli **[2]**.

Numerosi studi sono stati condotti in questo ambito; tuttavia, la maggior parte si concentra su *task* di classificazione delle emozioni, mentre solo una minoranza si dedica a modelli di regressione per l'analisi delle stesse.

Questo lavoro si propone di contribuire al campo dell'emotion annotation, con un focus sull'esplorazione delle capacità dei *large language model* (LLM) non specificamente addestrati per il riconoscimento delle emozioni. L'obiettivo principale è valutare in che misura questi modelli siano in grado di svolgere compiti di annotazione emotiva, analizzando l'efficacia e la coerenza nel rilevare e classificare diverse emozioni e i tratti morali. Inoltre, lo studio mira a individuare eventuali limitazioni o bias presenti nei modelli, aprendo la strada a possibili ottimizzazioni e sviluppi futuri nel loro impiego per questo specifico ambito applicativo.

# **1 Recupero e analisi Dataset**

Il dataset preso in considerazione è: [News Category Dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset) **[4]**. Il dataset rappresenta un archivio di oltre 200 mila notizie scritte dall'*HuffPost* utile per effettuare diversi task legati all'analisi linguistica e più in gnerale al *Natural Language Processing*. I dati presentano le seguenti *feature*:
- **category**: categoria di appartenenza in cui ricade l'articolo.
- **headline**: titolo dell'articolo.
- **authors**: lista di autori che hanno contribuito all'articolo.
- **link**: link all'articolo originale.
- **short_description**: descrizione del contenuto dell'articolo.
- **date**: data in cui è stato pubblicato l'articolo.

Per prima cosa sono stati caricati i dati e impostato un *seed* per garantire la riproducibilità dei risultati. Sono stati in seguito selezionati, in maniera casuale, 210 articoli al fine di trovare un equilibrio tra la bassa potenza computazionale e la complessità dei calcoli necessari al fine di ottenere risultati che siano il più preciso possibile.
"""

#setting the seed
import random
import numpy as np
import torch

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)

import pandas as pd
import json
import os
import kagglehub

set_seed(274)

# Download latest version of the data
path = kagglehub.dataset_download("rmisra/news-category-dataset")
print("Path to dataset files:", path)

#reading the dataset
data_path = "/root/.cache/kagglehub/datasets/rmisra/news-category-dataset/versions/3"
json_file = [f for f in os.listdir(data_path) if f.endswith('.json')][0]

# Construct the full path to the JSON file
full_path = os.path.join(data_path, json_file)
df_complete = pd.read_json(full_path, lines=True)

#selecting randomly only 200 news
# Calcoliamo il numero totale di categorie
total_categories = df_complete['category'].nunique()

# Calcoliamo il numero di campioni per categoria
n_samples_per_category = 210 // total_categories  # Uso della divisione intera

# Campionamento uniforme per categoria
grouped = df_complete.groupby('category')
df = grouped.apply(lambda x: x.sample(n=n_samples_per_category, random_state=274) if len(x) >= n_samples_per_category else x.sample(n=len(x), random_state=274))

# Reset dell'indice per pulire il DataFrame risultante
df.reset_index(drop=True, inplace=True)

df

"""## **1.1 Esplorazione dei dati**
Al fine di avere qualche *insight* delle notizie selezionate è stata effettuata una semplice esplorazione del dataset ridotto. In particolare, si è analizzata la distribuzione delle categorie degli articoli.  
"""

import matplotlib.pyplot as plt

category_counts = df['category'].value_counts()

plt.figure(figsize=(12, 6))
plt.bar(category_counts.index, category_counts.values)
plt.title('Distribution of News Categories')
plt.xlabel('Category')
plt.ylabel('Frequency')
_ = plt.xticks(rotation=45, ha='right')

"""Dal grafico di cui sopra è possibile notare come le notizie prese in considerazione siano equamente distribuite tra le varie categorie.

# **2. Meta Llama 3.1**

Il primo modello utilizzato per l'annotazione delle emozioni è `Meta Llama 3.1`. Meta ha introdotto `Meta Llama 3.1`, come nuova generazione dei suoi precedenti *language model*. Esistono due versioni del modello: una presenta 8 miliardi di parametri; la seconda, più complessa ne presenta 70 miliardi. Questi modelli sono stati progettati sia in versione pre-addestrata che ottimizzata per seguire istruzioni specifiche, rendendoli adatti a un'ampia gamma di applicazioni. Rispetto alla generazione precedente, Llama 3 offre significativi miglioramenti, infatti, ha raggiunto prestazioni di alto livello su molti *benchmark* noti **[5]**. Queste caratteristiche lo rendono uno strumento estremamente versatile per diversi casi d'uso e anche uno dei motivi per i quali è stato selezionato per gli scopi di questo progetto.

La prima operazione da effettuare è caricare il modello dal sito [*HuggingFace*](https://huggingface.co/).
"""

#Importing model from Hugging Face
!pip install huggingface_hub

from huggingface_hub import login

# it is necessary to login wiht your personal token to have access at the various models
token = "insert_your_hugging_face_token"
login(token=token)

# Installling useful packages
!pip install -U accelerate
!pip install -U bitsandbytes

from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

from transformers import AutoTokenizer, AutoModelForCausalLM
from transformers import BitsAndBytesConfig

# Configuration for 8-bit quantization
bnb_config = BitsAndBytesConfig(
    load_in_8bit=True,
)

# Tokenizer
tokenizer_llama = AutoTokenizer.from_pretrained("meta-llama/Llama-3.1-8B-Instruct")


# Model with the 8-bit configuration
model_id_llama = "meta-llama/Llama-3.1-8B-Instruct"
model_llama = AutoModelForCausalLM.from_pretrained(
    model_id_llama,
    quantization_config=bnb_config,
    device_map="auto"
)

"""La versione che è stata caricata del modello `Meta Llama 3.1` è caratterizzata dalla quantizzazione a 8 bit. Tale specifica è necessaria per ridurre la grandezza del modello andandone a diminuire, di conseguenza la complessità computazionale. Attuando questa riduzione di complessità è necessario specificare che vi è anche una perdita di precisione nei calcoli effettuati che però viene considerata accettabile **[6]**.

In seguito, vengono definiti dei metodi utili per l'esecuzione del modello e quindi dell'anotazione dei testi. I metodi, descritti di seguito, risultano essere generali nel senso che sono stati poi utilizzati anche per l'esecuzione dei modelli successivi.

Il primo metodo sviluppato è `generate_prompt`che consente, dato il *template* del *prompt* più adatto per il modello specifico, di creare la richiesta in forma completa, ovvero, inserendo all'interno del *template* anche il testo che il modello deve analizzare. I diversi prompt utilizzati sono specificati nell'appendice **A** del *notebook*.
"""

def generate_prompt(prompt_template, headline, short_description):
    # Concatenate headline and short_description
    text = f"{headline}. {short_description}"
    prompt = prompt_template.replace("{texts}", text)
    return prompt

"""Il metodo `emotion_evaluation` è il cuore del progetto. Come è facilmente intuibile è grazie a questa funzione che viene effettuata l'annotazione da parte dei vari modelli. Al modello viene fornito un *prompt* strutturato, che rappresenta la richiesta per l'analisi delle emozioni. Questo serve come punto di partenza per generare una risposta testuale. Il modello elabora il *prompt* e produce un'*output*, che viene decodificato per ottenere un testo leggibile. Durante questo processo, eventuali elementi non necessari (come il prompt stesso o parti del testo non pertinenti generate dai diversi modelli utilizzati in seguito) vengono eliminati per migliorare la chiarezza della risposta.

Poiché diversi *language model* possono presentare variazioni nel formato delle risposte (ad esempio, marcatori specifici o delimitatori), il metodo è stato progettato per gestire queste differenze in modo flessibile. Per ogni modello, vengono applicati accorgimenti specifici per estrarre correttamente le informazioni richieste.

Il testo generato dal modello viene analizzato per identificare la sezione contenente le informazioni sulle emozioni (o tratti morali). Questa sezione è delimitata da indicatori specifici (es. `###BEGIN` e `###END`). All'interno di questa sezione, vengono identificati i nomi delle emozioni (o tratti morali) e i loro punteggi associati.

Una volta identificata la lista degli elementi di interesse, questi vengono normalizzati e organizzate in un formato strutturato, sotto forma di un dizionario. Ogni emozione (o tratto morale) è associata a un punteggio numerico che ne indica l'intensità.
"""

import re
import pandas as pd

def emotion_evaluation(model_id, model, tokenizer, prompt, generation_params):

    prompt_template = prompt

    while True:

        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        output = model.generate(**inputs, **generation_params)

        # Decode the output
        emotion = tokenizer.decode(output[0], skip_special_tokens=True)

        print("Answer: ", emotion)

        # Remove the prompt from the response if it is present
        if prompt in emotion:
            emotion = emotion.replace(prompt, "").strip()

        # Handle specific model output useless parts of the outpu
        if "gemma" in str(model_id):
            emotion = emotion.split("model", 1)[-1].strip()

        if "mistral" in str(model_id):
            emotion = emotion.split("[\INST]", 1)[-1].strip()

        # Extract the block between ###BEGIN and ###END
        #print(emotion)
        match = re.search(r'###BEGIN(.*?)###END', emotion, re.DOTALL)
        if match:
            emotion_list = match.group(1).strip()

            # put the results in a dictionary
            emotion_dict = {}
            for line in emotion_list.splitlines():
                line = line.strip().lstrip('-').strip()
                key_value = re.match(r'(.*?)=\s*([0-9]*\.?[0-9]+)', line)
                if key_value:
                    key, value = key_value.groups()
                    emotion_dict[key.strip()] = float(value)
            return emotion_dict  # Return the dictionary directly
        else:
            continue  # Retry in case delimiters are not found

"""Per effettuare una analisi più appronfondita sulle capacità dei diversi modelli sull'anotare le emozioni si è pensato di fare in modo che questi siano eseguiti sotto tre diverse configuraozioni di *decoding*:

1. **Greedy Decoding**: Questo metodo seleziona, ad ogni passaggio, il token con la probabilità più alta tra quelli previsti dal modello.
2. **Top-k Sampling**: In questo metodo, il modello considera solo i primi k token con la probabilità più alta, ignorando gli altri.
3. **Top-p Sampling**: Con questo metodo, il modello considera i token cumulativamente fino a raggiungere una probabilità complessiva pari a $p$.


"""

#top k-sampling
generation_params_top_k = {
    "max_new_tokens": 400,
    "do_sample": True,
    "top_k": 50
}

"""Top-K *sampling* limita lo spazio di selezione delle parole successive alle  *k* parole più probabili. Il parametro `do_sample` impostato con valore di verità `True` permette di campionare in modo stocastico tra le *k* opzioni, introducendo una componente di casualità. Tale configurazione genera output più vari rispetto all'approccio *greedy*."""

#greedy params
generation_params_greedy = {
    "max_new_tokens": 400,
    "do_sample": False
}

"""Il *greedy* decoding è una tecnica che sceglie sempre la parola la probabilità più alta ad ogni passo della generazione. Il parametrò `do_sample`, al contrario della decodifica Top-k, è impostato con valore `False` escludendo quindi ogni tipo di casualità e varietà nella generazione degli output."""

#creating different outputs generation methods changing different parameters
generation_params_p_sampling = {
    "max_new_tokens": 400,
    "do_sample": True,
    "temperature": 0.7,
    "top_p": 0.9
}

"""Il metodo di decodifica Top-p *sampling* seleziona dinamicamente un sottoinsieme di parole candidate tali che la loro somma cumulativa di probabilità raggiunga la soglia definita dal parametro `top_p`, in questo caso impostato a 0.9. La combinazione con una temperatura non eccessivamente alta (0.7) aggiunge una componente di casualità controllata ma evita generazioni troppo casuali, mantenedo il focus sulle interpretazioni plausibili."""

# Creating an empty DataFrame with the specified columns
columns = ['index', 'content_id', 'Paragraph', 'language', 'event', 'subject',
           'care_scores', 'harm_scores', 'fairness_scores', 'cheating_scores',
           'loyalty_scores', 'betrayal_scores', 'authority_scores', 'subversion_scores',
           'purity_scores', 'degradation_scores', 'anticipation', 'trust', 'disgust',
           'joy', 'optimism', 'surprise', 'love', 'anger', 'sadness', 'pessimism',
           'fear', 'no emotion', 'no moral', 'url_news']

"""Altra funzione molto importante è quella adibita alla generazione del *dataset* dei risultati per ogni modello: `generate_emotion_morality_dataset`. Il metodo, indipendentemente dal modello, va a creare per ogni testo un *template* per la generica riga che verrà inserità nel dataset. Lo schema utilizzato è stato ispirtato dal lavoro descritto in E2MoCase **[1]**. In seguito vengono generati due prompt distinti: il primo per l'analisi dei tratti morali; il secondo per l'analisi delle emozioni. Si è deciso di svolgere separatamente l'analisi per fare in modo che i modelli potessero concentrarsi su i task singolarment evitando così una possibile complicazione e minore accuratezza dei risultati.

Viene poi eseguito il modello per entrambi i tipi di annotazione e i risultati vengono poi uniti all'interno del dataset di valutazione finale.
"""

import pandas as pd

def generate_emotion_morality_dataset(df, model_id, model, tokenizer, prompt_morality, prompt_emotions, generation_params, columns, num_samples=100):


    # Dataset initialization
    evaluations_df = pd.DataFrame(columns=columns)

    # for every text
    for i in range(len(df))):
        print(f"Evaluating text number {i}")

        # Ottieni i dati di input
        headline = df['headline'].iloc[i]
        short_description = df['short_description'].iloc[i]
        url = df['link'].iloc[i]
        text = f"{headline}. {short_description}"

        # template for a single ro
        row_data = {
            'index': i,
            'content_id': i,
            'Paragraph': text,
            'language': 'English',
            'event': None,
            'subject': None,
            'care_scores': None,
            'harm_scores': None,
            'fairness_scores': None,
            'cheating_scores': None,
            'loyalty_scores': None,
            'betrayal_scores': None,
            'authority_scores': None,
            'subversion_scores': None,
            'purity_scores': None,
            'degradation_scores': None,
            'anticipation': None,
            'trust': None,
            'disgust': None,
            'joy': None,
            'optimism': None,
            'surprise': None,
            'love': None,
            'anger': None,
            'sadness': None,
            'pessimism': None,
            'fear': None,
            'no emotion': None,
            'no moral': None,
            'url_news': url
        }

        # Generating 2 different prompts one for morality traits one for emotions
        morality_prompt = generate_prompt(prompt_morality, headline, short_description)
        emotion_prompt = generate_prompt(prompt_emotions, headline, short_description)

        # Evaluating moral traits
        morality_scores = emotion_evaluation(model_id, model, tokenizer, morality_prompt, generation_params)
        for trait in ['Care', 'Harm', 'Fairness', 'Cheating', 'Loyalty', 'Betrayal',
                      'Authority', 'Subversion', 'Purity', 'Degradation']:
            row_data[f"{trait.lower()}_scores"] = morality_scores.get(trait, 0)
        row_data['no moral'] = morality_scores.get('Neutral', 0)

        # Evaluating emotions
        emotion_scores = emotion_evaluation(model_id, model, tokenizer, emotion_prompt, generation_params)
        for emotion in ['Anticipation', 'Trust', 'Disgust', 'Joy', 'Optimism', 'Surprise',
                        'Love', 'Sadness', 'Pessimism', 'Fear', 'Anger']:
            row_data[emotion.lower()] = emotion_scores.get(emotion, 0)
        row_data['no emotion'] = emotion_scores.get('Neutral', 0)

        # adding the row to the results
        evaluations_df = pd.concat([evaluations_df, pd.DataFrame([row_data])], ignore_index=True)

    return evaluations_df

llama_emotions_evaluations_df = generate_emotion_morality_dataset(df, model_id_llama, model_llama, tokenizer_llama, prompt_morality, prompt_emotions, generation_params_greedy, columns)

"""Per verificare la corretta esecuzione dell'annotazione e creazione del dataframe contenente i valori assegnati dal modello, è stato sviluppato un metoto `nan_counter` per verificare la presenza di eventuali anomale nella generazione dei risultati.

Le uniche *feature* che possiamo lasciare a `NaN` sono:
- `event`: ovvero l'evento che viene descritto all'interno dell'articolo.
- `subject`: il soggetto dell'articolo preso in considerazione.


"""

import matplotlib.pyplot as plt

def nan_counter(df):
    #change NaN with 0.0
    nan_counter_column = df.isna().sum()
    # Creazione del grafico
    plt.figure(figsize=(30, 6))
    plt.bar(nan_counter_column.index, nan_counter_column.values)
    plt.xlabel('Column')
    plt.ylabel('NaN')
    plt.title('Counting NaN')
    plt.show()

nan_counter(llama_greedy)
colonne_con_nan = llama_greedy.columns[llama_greedy.isna().any()].tolist()

# Stampa i nomi delle colonne
print("Colonne con valori NaN:", colonne_con_nan)

"""Di seguito riportato del codice ausiliario per il salvataggio su file `.csv` del dataframe dei risultati delle diverse run dei modelli. Si è adottata questa metodologia per evitare una riesecuzione dei modelli e avere un accesso più rapido ai risultati tramite il loro caricamento da file."""

#saving the df as a csv to be more fast for the next try
import csv
llama_emotion_evaluations_df.to_csv('df_llama_results_greedy.csv', index=False, quoting=csv.QUOTE_ALL)

import csv
import pandas as pd

llama_top_k = pd.read_csv('/content/df_llama_results_top_k.csv')
llama_top_k_neutral = pd.read_csv('/content/df_llama_results_top_k_neutral-2.csv')
llama_greedy = pd.read_csv('/content/df_llama_results_greedy.csv')
llama_greedy_neutral = pd.read_csv('/content/df_llama_results_greedy_neutral.csv')
llama_top_p = pd.read_csv('/content/df_llama_results_top_p.csv')
llama_top_p_neutral = pd.read_csv('/content/df_llama_results_top_p_neutral.csv')

"""## **2.1 Meta Llama 3.1 result analysis**

In questa sezione vengono analizzate le performance del modello Meta LLaMA 3.1 nell'annotazione delle emozioni e dei tratti morali presenti nei testi proposti. L'obiettivo principale è valutare separatamente le capacità del modello nei due ambiti, evidenziando punti di forza e aree di miglioramento.

Per garantire un'analisi approfondita dei risultati generati dal modello, sono stati adottati diversi approcci e strumenti analitici, tra cui:

- **Creazione di statistiche descrittive**: È stata elaborata una tabella contenente statistiche come il numero medio di emozioni e tratti morali rilevati dal modello all'interno dei testi.
- **Presenza specifica di emozioni e tratti morali**: Una tabella è stata creata per identificare la frequenza di ciascuna emozione e tratto morale all'interno dei testi analizzati.
- **Analisi della correlazione**: Sono state calcolate le correlazioni tra emozioni per verificare la coerenza delle annotazioni prodotte dal modello. Un'analisi analoga è stata condotta separatamente per i tratti morali.
- **Distribuzione delle emozioni e dei tratti morali**: La distribuzione delle annotazioni è stata esaminata per verificare la prevalenza di specifiche emozioni o tratti morali nei testi o se queste categorie siano considerate in modo uniforme.
- **Interpretazione della classe** `no_emotion` **e** `no_moral`: È stata effettuata un'analisi della correlazione tra queste classi e le altre emozioni o tratti morali, per comprendere come il modello interpreta la loro assenza.
- **Confronto tra emozioni positive e negative**: Sono state confrontate le annotazioni relative alle emozioni positive e negative per valutare eventuali squilibri o tendenze nel comportamento del modello.

Queste analisi forniscono una visione dettagliata delle capacità del modello e consentono di identificare eventuali aree di miglioramento per futuri sviluppi.

"""

#divide moral traits and emotion
moral_traits = ['care_scores', 'harm_scores', 'fairness_scores', 'cheating_scores',
           'loyalty_scores', 'betrayal_scores', 'authority_scores', 'subversion_scores',
           'purity_scores', 'degradation_scores', 'no moral']

emotions = ['anticipation', 'trust', 'disgust',
           'joy', 'optimism', 'surprise', 'love', 'anger', 'sadness', 'pessimism',
           'fear', 'no emotion']

"""### **2.1.1 Statistiche dei risultati di Llama 3.1**

Per calcolare le statistiche si sono prese in considerazione i seguenti aspetti.

- Numero di testi analizzati
- Numero medio di *token*
- Numero medio di emozioni riscontrate nei testi
- Numero medio di tratti morali riscontrati nei testi

Queste analisi sono state fatte per tutte le *run* del modello eseguite con le diverse configurazioni.

Il metodo `average_number_of_tokens` calcola il numero medio di *token* (unità linguistiche più piccole in cui viene suddiviso un testo) generati da un *tokenizer* quando applicato a un *dataset*. Nel caso di LLama 3.1 la tecnica utilizzata per la tokenizzazione e il BPE (*Byte Pair Encoding*) **[7]**. Per ogni riga del *dataset*, combina il contenuto delle colonne `headline` e `short_description` in un unico testo, lo tokenizza e conta il numero di *token*. Alla fine, restituisce la media di questi conteggi considerando tutte le righe del dataset.


"""

#average number of tokens
def average_number_of_tokens(data, tokenizer):

    token_sum = 0
    for i in range(0, len(df)):
      headline = df['headline'].iloc[i]
      short_description = df['short_description'].iloc[i]
      text = f"{headline}. {short_description}"
      tokens = tokenizer.tokenize(text)
      num_tokens = len(tokens)
      token_sum += num_tokens

    return token_sum/len(df)

"""Il metodo `average_number_of_emotions` calcola la media di quante emozioni sono state rilevate all'interno dei testi nalizzati. Analogamente, `average_number_of_moral_traits` fa la stessa cosa ma per i tratti morali."""

#average number of emotions
def average_number_of_emotions(df, emotion_columns):

    df['num_emotions_present'] = df[emotion_columns].gt(0).sum(axis=1)
    mean_emotions_per_text = df['num_emotions_present'].mean()

    return mean_emotions_per_text

#average numbers of moral traits
def average_number_of_moral_traits(df, moral_traits):

    df['num_moral_traits_present'] = df[moral_traits].gt(0).sum(axis=1)
    mean_moral_traits_per_text = df['num_moral_traits_present'].mean()

    return mean_moral_traits_per_text

"""Il metodo descritto di seguito sfrutta i precedenti per creare la tabella di statistiche che viene descritta nella sezione successiva."""

def create_table_of_statistics(results, names, tokenizer, emotions, moral_traits):

    statistics = []

    for df, name in zip(results, names):

        avg_tokens = average_number_of_tokens(df, tokenizer)
        avg_emotions = average_number_of_emotions(df, emotions)
        avg_moral_traits = average_number_of_moral_traits(df, moral_traits)

        statistics.append({
            'Dataset': name,
            'Number of Texts': len(df),
            'Average Tokens': avg_tokens,
            'Average Emotions': avg_emotions,
            'Average Moral Traits': avg_moral_traits
        })

    stats_df = pd.DataFrame(statistics).set_index('Dataset')

    return stats_df

dfs_llama = [llama_greedy, llama_greedy_neutral, llama_top_k, llama_top_k_neutral, llama_top_p, llama_top_p_neutral]
dfs_names_llama = ["LLama Greedy", "LLama Greedy Neutral", "LLama Top K", "LLama Top K Neutral", "LLama Top P", "LLama Top P Neutral"]
stats_for_llama = create_table_of_statistics(dfs_llama, dfs_names_llama , tokenizer_llama, emotions, moral_traits)
stats_for_llama

"""
Dall'analisi dei risultati riportati nella tabella emerge una chiara differenza nelle performance del modello Meta LLaMA 3.1 in base al metodo di inferenza utilizzato. Il numero medio di emozioni e tratti morali rilevati varia significativamente tra le configurazioni: il metodo **Greedy** si dimostra più conservativo, annotando meno emozioni (1.80) e tratti morali (2.20) rispetto ai metodi più esplorativi come **Top-k** e **Top-p**, che raggiungono valori più alti.

L'aggiunta della modalità **Neutral** in ciascun approccio incrementa ulteriormente la ricchezza delle annotazioni, ciò potrebbe suggerire che questa configurazione favorisca una maggiore sensibilità del modello nel rilevare dettagli emotivi e morali nei testi. In generale, i metodi **Top K** e **Top P** sembrano offrire annotazioni più ricche e diversificate rispetto a **Greedy**, rendendoli più adatti per applicazioni che richiedono maggiore granularità. Resta però da verificare se l'aumento di annotazioni corrisponda a una maggiore accuratezza e coerenza rispetto ai dati di riferimento.

Il metodo `create_moral_traits_count_tables` ha lo scopo di analizzare e riassumere in modo chiaro la presenza dei tratti morali nei diversi dataset. Il metodo prende in considerazione i diversi dataset dei risultati e calcola quante volte ogni tratto morale è stato identificato all'interno di ciascun dataset. Una volta determinato il numero di occorrenze per ciascun tratto morale, il metodo calcola anche la percentuale di ciascun tratto rispetto al totale delle annotazioni di quel dataset. Questo aiuta a capire quali tratti sono più comuni e quali meno rappresentati. I risultai ottenuti vengono poi inseriti all'interno di una tabella riassuntiva analizzata nella sessione successiva."""

def create_moral_traits_count_tables(results, names, moral_traits):

    statistics = []

    for df, name in zip(results, names):
        # counting the occurence for each moral trait
        counts = (df[moral_traits] > 0).sum()

        # summing the occurrence
        total_counts = counts.sum()

        dataset_stats = {'Dataset': name}
        for trait in moral_traits:
            dataset_stats[f"{trait}_Count"] = counts[trait]
            dataset_stats[f"{trait}_Percentage"] = (counts[trait] / total_counts * 100).round(2)

        statistics.append(dataset_stats)

    stats_df = pd.DataFrame(statistics).set_index('Dataset')

    return stats_df

moral_trait_tables = create_moral_traits_count_tables(dfs_llama, dfs_names_llama, moral_traits)
print(moral_trait_tables.to_string())

"""
Si nota che l'introduzione della modalità "Neutrale" nelle configurazioni Greedy aumenta drasticamente la frequenza della classe `no_moral` (fino al 24.05%), riducendo di conseguenza la rilevazione degli altri tratti morali. Le configurazioni LLama Top-k e Top-p, sia con che senza Neutral, rilevano una maggiore varietà di tratti morali, dimostrando una maggiore sensibilità e ricchezza di annotazioni. Tra i tratti morali, *Fairness* e *Authority* risultano essere i più frequentemente rilevati, con percentuali che arrivano rispettivamente al 16.82% e 14.33% nelle configurazioni LLama Top-k e Top-p. D'altro canto, tratti come *Betrayal* e *Cheating* sono tra i meno annotati, suggerendo una possibile difficoltà del modello nel riconoscerli o una loro minore rappresentazione nei dati. In conclusione, i metodi esplorativi come LLama Top-k e Top-p offrono risultati più ricchi e variegati, dimostrandosi più efficaci per l'analisi dei tratti morali, mentre la modalità Neutral risulta utile per identificare testi privi di moralità, a scapito di una riduzione nella granularità delle annotazioni dei tratti morali presenti.

Osservando la tabella relativa al numero medio di tratti morali rilevati dal modello, si nota che per ogni configurazione l'aggiunta dell'opzione di considerare un tratto morale "neutrale" porta a un aumento significativo del numero medio di tratti morali rilevati. Questo fenomeno è spiegabile dal fatto che il tratto `no_neutral` viene riconosciuto nella maggior parte dei testi, contribuendo in modo consistente all'incremento complessivo delle annotazioni medie per testo.

Questa osservazione suggerisce che il modello, quando configurato per includere la classe "neutrale", tende a classificare un numero maggiore di testi come contenenti tratti morali, sebbene ciò possa ridurre la granularità delle altre categorie. Pertanto, il comportamento del modello con l'opzione "neutrale" evidenzia una predisposizione a rilevare la presenza di moralità generica piuttosto che distinguere in modo preciso i tratti morali specifici.

"""

def create_emotions_count_tables(dataframes, names, emotion_columns):

    statistics = []

    for df, name in zip(dataframes, names):

        counts = (df[emotion_columns] > 0).sum()

        total_counts = counts.sum()

        dataset_stats = {'Dataset': name}
        for emotion in emotion_columns:
            dataset_stats[f"{emotion}_Count"] = counts[emotion]
            dataset_stats[f"{emotion}_Percentage"] = (counts[emotion] / total_counts * 100).round(2)

        statistics.append(dataset_stats)

    stats_df = pd.DataFrame(statistics).set_index('Dataset')

    return stats_df

emotion_tables = create_emotions_count_tables(dfs_llama, dfs_names_llama, emotions)
print(emotion_tables.to_string())

"""
Dai dati riportati emerge una chiara differenza tra le configurazioni con e senza l'opzione "Neutral" come nel caso dei tratti morali. Le configurazioni senza "Neutral" tendono a rilevare un numero maggiore di emozioni specifiche. In particolare, Optimism e Trust risultano tra le emozioni più frequentemente annotate, raggiungendo percentuali significative nelle configurazioni Top-k e Top-p. Al contrario, l'aggiunta della modalità "Neutral" porta a una notevole riduzione della rilevazione di emozioni specifiche, con un aumento significativo della classe No Emotion, che raggiunge il 28.17% in LLama Greedy Neutral. Questo indica che il modello, con l'opzione "Neutral", diventa più cauto nel rilevare emozioni, attribuendo una maggiore neutralità ai testi.

Come per il caso dei tratti morali, anche per l'annotazione delle emozioni, l'aumento del numero medio delle emozioni rilevate è dovuto ad un drastico aumento della rilevazione dell'emozioni `no_emotions`.

L'analisi dei risultati evidenzia che il comportamento del modello Meta LLaMA 3.1 varia significativamente in base al metodo di inferenza e all'utilizzo dell'opzione "Neutral". Le configurazioni senza "Neutral" tendono a essere più ricche e granulari, rilevando un numero maggiore di emozioni e tratti morali specifici. Questi metodi, in particolare Top-k e Top-p, risultano più adatti per applicazioni che richiedono un'analisi dettagliata e diversificata, garantendo una migliore rappresentazione delle caratteristiche emotive e morali nei testi.

Per una più facile visualizzazione dei dati appena descritti sono stati creati due metodi per la rappresentazione grafica dei risultati."""

import matplotlib.pyplot as plt

def emotion_occurrence(df, title, selected_columns):

    df = df[selected_columns].astype(float)
    # Counting the occurrence for each emotion
    emotion_counts = (df.iloc[:, :].astype(float) != 0).sum()

    plt.figure(figsize=(15, 8))
    bars = plt.bar(emotion_counts.index, emotion_counts, color="lightblue", edgecolor = 'black')  # Use a single color here

    plt.grid(axis = 'y')
    plt.title(title)
    plt.ylim(0, emotion_counts.max() + 1)
    plt.xticks(ticks=range(len(emotion_counts.index)), labels=emotion_counts.index, rotation=45, ha='right')

    plt.show()

import matplotlib.pyplot as plt
import numpy as np

def comparison_emotion_occurrences(dfs, model_names, title):
    # Counting occurrences for each emotion in each DataFrame
    emotion_counts = [df.iloc[:, :].astype(float).ne(0).sum() for df in dfs]

    # Emotion labels (assumes all DataFrames have the same columns)
    emotions = emotion_counts[0].index

    # Define different colors for each model
    colors = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854']

    # Setting the width and position of the bars
    bar_width = 0.30
    x = np.arange(len(emotions))

    plt.figure(figsize=(15, 8))

    # Create bars for each model with black edges
    for i, counts in enumerate(emotion_counts):
        plt.bar(x + i * bar_width, counts, width=bar_width, color=colors[i], edgecolor="black", label=model_names[i])

    # Graph settings
    plt.title(title)
    plt.grid(axis = 'y')
    plt.xticks(x + bar_width * (len(dfs) - 1) / 2, emotions, rotation=45, ha='right')
    plt.ylim(0, max([counts.max() for counts in emotion_counts]) + 1)
    plt.legend(title="Models")

    plt.show()

emotion_occurrence(llama_greedy, 'Emotion Distribution (Greedy Decoding, No Neutral)', emotions)
emotion_occurrence(llama_greedy_neutral, 'Emotion Distribution (Greedy Decoding)', emotions)

emotion_occurrence(llama_greedy, 'Moral Traits Distribution (Greedy Decoding, No Neutral)', moral_traits)
emotion_occurrence(llama_greedy_neutral, 'Moral Traits Distribution (Greedy Decoding)', moral_traits)

"""Dal grafico relativo al *Greedy Decoding* si può notare una diminuzione sostanziale nella rilevazione delle emozioni nel momento in cui viene inserita la possibilità di considerare delle emozioni (o tratti morali) neutrali. Si può notare inoltre che le emozioni neutrali risultano sovrastare, in termini di occorrenze, il numero delle altre emozioni da rilevare."""

emotion_occurrence(llama_top_k, 'Emotion Distribution (Top K = 50, No Neutral)', emotions)
emotion_occurrence(llama_top_k_neutral, 'Emotion Distribution (Top K = 50)', emotions)

emotion_occurrence(llama_top_k, 'Moral Trait Distribution (Top K = 50, No Neutral)', moral_traits)
emotion_occurrence(llama_top_k_neutral, 'Moral Trait Distribution (Top K = 50)', moral_traits)

"""Per la configurazione di decoding Top-k la diminuzione delle occorrenze delle emozioni specifiche rispetto alle neutrali risulta essere meno marcata. Anche in questo caso, tuttavia, l'emozione neutrale prevale su tutte le altre nel momento in cui questa viene presa in considerazione."""

emotion_occurrence(llama_top_p, 'Emotion Distribution (Top P)', emotions)
emotion_occurrence(llama_top_p_neutral, 'Emotion Distribution (Top P)', emotions)

emotion_occurrence(llama_top_p, 'Moral Trait Distribution (Top P)', moral_traits)
emotion_occurrence(llama_top_p_neutral, 'Moral Trait Distribution (Top P)', moral_traits)

"""Anche nel caso del Top-p *sampling*, la riduzione delle occorrenze delle emozioni specifiche rispetto a quelle neutrali risulta poco significativa. Questo potrebbe indicare una tendenza intrinseca della strategia di *greedy decoding* a privilegiare le emozioni di tipo neutrale, indipendentemente dal contenuto del testo analizzato. Sulla base di queste osservazioni, si può ritenere che la strategia di *greedy decoding* sia attualmente la meno affidabile tra le tre prese in considerazione per il modello LLaMA 3.1.

Successivamente sono stati effettuati dei confronti grafici che tengono conto sia delle diverse configurazioni di decoding sia della presenza o meno dell'elemento neutrale all'interno delle classi di emozioni che si vogliono annotare.
"""

#comparing two distribution at a time for neutral and non neutral run
dfs_moral_trait_llama_greedy = [llama_greedy[moral_traits].astype(float), llama_greedy_neutral[moral_traits].astype(float)]
dfs_moral_trait_llama_top_k = [llama_top_k[moral_traits].astype(float),llama_top_k_neutral[moral_traits].astype(float)]
dfs_moral_trait_llama_top_p = [llama_top_p[moral_traits].astype(float),llama_top_p_neutral[moral_traits].astype(float)]

#comparing all non neutral run
dfs_moral_trait_all_models = [llama_greedy[moral_traits].astype(float),llama_top_k[moral_traits].astype(float),llama_top_p[moral_traits].astype(float) ]

#comparing all neutral run
dfs_moral_trait_neutral_models = [llama_greedy_neutral[moral_traits].astype(float),llama_top_k_neutral[moral_traits].astype(float),llama_top_p_neutral[moral_traits].astype(float) ]

#greedy comparison
labels = ['Greedy (No Neutral)', 'Greedy']
comparison_emotion_occurrences(dfs_moral_trait_llama_greedy, labels, "Moral Traits Distribution Comparison Greedy")


#top k comparison
labels = ['Top K (No Neutral)', 'Top K']
comparison_emotion_occurrences(dfs_moral_trait_llama_top_k, labels, "Moral Traits Distribution Comparison Top K = 50")

#top p comparison
labels = ['Top P (No Neutral)', 'Top P']
comparison_emotion_occurrences(dfs_moral_trait_llama_top_p, labels, "Moral Traits Distribution Comparison Top P")

#comparison all non neutral model
labels = ['Greedy', 'Top K', 'Top P']
comparison_emotion_occurrences(dfs_moral_trait_all_models, labels, "Moral Traits Distribution Comparison All Models")

#comparison all neutral model
labels = ['Greedy Neutral', 'Top K Neutral', 'Top P Neutral']
comparison_emotion_occurrences(dfs_moral_trait_neutral_models, labels, "Moral Traits Distribution Comparison All Neutral Models")

"""Dal confronto grafico si può evincere che il metodo di *decoding* che è in grado di individuare meno tratti morali risulta essere il *greedy* come già visto anche grazie alle analisi numeriche. Il metodo di *decoding* Top-p sembra individuare più tratti morali rispetto Top-k. Considerando la possibilità di neutralità nei testi la strategia Top-p di *decoding* risulta essere più efficace nell'individuare più tratti morali rispetto agli altri."""

# Comparing two distributions at a time for neutral and non-neutral run
dfs_emotion_llama_greedy = [llama_greedy[emotions].astype(float), llama_greedy_neutral[emotions].astype(float)]
dfs_emotion_llama_top_k = [llama_top_k[emotions].astype(float), llama_top_k_neutral[emotions].astype(float)]
dfs_emotion_llama_top_p = [llama_top_p[emotions].astype(float), llama_top_p_neutral[emotions].astype(float)]

# Comparing all non-neutral runs
dfs_emotion_all_models = [llama_greedy[emotions].astype(float), llama_top_k[emotions].astype(float), llama_top_p[emotions].astype(float)]

# Comparing all neutral runs
dfs_emotion_neutral_models = [llama_greedy_neutral[emotions].astype(float), llama_top_k_neutral[emotions].astype(float), llama_top_p_neutral[emotions].astype(float)]

# Greedy comparison
labels = ['Greedy (No Neutral)', 'Greedy']
comparison_emotion_occurrences(dfs_emotion_llama_greedy, labels, "Emotions Distribution Comparison Greedy")

# Top K comparison
labels = ['Top K (No Neutral)', 'Top K']
comparison_emotion_occurrences(dfs_emotion_llama_top_k, labels, "Emotions Distribution Comparison Top K = 50")

# Top P comparison
labels = ['Top P (No Neutral)', 'Top P']
comparison_emotion_occurrences(dfs_emotion_llama_top_p, labels, "Emotions Distribution Comparison Top P")

# Comparison all non-neutral models
labels = ['Greedy', 'Top K', 'Top P']
comparison_emotion_occurrences(dfs_emotion_all_models, labels, "Emotions Distribution Comparison All Models")

# Comparison all neutral models
labels = ['Greedy Neutral', 'Top K Neutral', 'Top P Neutral']
comparison_emotion_occurrences(dfs_emotion_neutral_models, labels, "Emotions Distribution Comparison All Neutral Models")

"""Analogamente al caso dei tratti morali, è possibile verificare che il Top-p *sampling* risulta essere la modalità di decodifica in grado di rilevare più emozioni all'interno dei testi.

### **2.1.2 Analisi della correlazione**

L'analisi delle correlazioni rappresenta un passaggio fondamentale per esplorare le relazioni tra variabili in un dataset complesso, come quello derivante dall'annotazione delle emozioni e dei tratti morali forniti dai modelli linguistici di grandi dimensioni (LLM). In questo studio, utilizziamo il coefficiente di correlazione di Spearman, una misura non parametrica che valuta la monotonicità tra due variabili, per esaminare i legami tra emozioni e, separatamente, tra tratti morali. Questo tipo di correlazione è particolarmente utile perché consente di individuare relazioni che non devono necessariamente essere lineari e non richiede la normalizzazione dei dati, come invece accade per il coefficiente di Pearson **[8]**.

Le emozioni rappresentano una componente chiave nella comprensione del linguaggio naturale. Attraverso la matrice di correlazione, esploreremo la presenza di relazioni significative tra diverse emozioni annotate, come "gioia", "tristezza" o "paura". Questo ci permetterà di identificare eventuali associazioni o schemi ricorrenti, utili per comprendere come gli LLM percepiscono e attribuiscono emozioni nei testi.

I tratti morali, basati su principi etici e comportamentali (ad esempio, "cura", "lealtà", "autorità"), offrono una prospettiva diversa ma complementare rispetto alle emozioni. Attraverso la matrice di correlazione, valuteremo le interazioni tra questi tratti, cercando di comprendere se vi siano pattern che riflettano un'interconnessione tra i valori morali nei dati annotati.

L'analisi della matrice di correlazione fornirà, quindi, una base quantitativa per riflettere sulle capacità degli LLM nel catturare sfumature emotive e morali, aiutandoci a delineare il potenziale e le criticità di questi strumenti nel campo del linguaggio naturale.
"""

import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import numpy as np

def correlation_matrix_neutral(df, title):
    n = df.shape[1]
    corr_matrix = np.zeros((n, n))  # Inizializziamo la matrice delle correlazioni

    # Iteriamo su tutte le coppie di colonne
    for i in range(n):
        for j in range(i, n):  # Include anche (i, i) per la diagonale
            if np.all(df.iloc[:, i] == df.iloc[:, i][0]) or np.all(df.iloc[:, j] == df.iloc[:, j][0]):
                # Se una delle colonne è costante (valori tutti uguali), la correlazione non è definita
                corr_matrix[i, j] = corr_matrix[j, i] = np.nan
            else:
                # Calcolo della correlazione di Spearman
                corr, _ = stats.spearmanr(df.iloc[:, i], df.iloc[:, j], nan_policy='omit')
                corr_matrix[i, j] = corr_matrix[j, i] = corr

    # Gestione dei NaN per garantire la visibilità nel grafico
    corr_matrix_display = np.where(np.isnan(corr_matrix), 0, corr_matrix)  # Sostituiamo NaN con 0 per il grafico
    annotations = np.where(np.isnan(corr_matrix), "NaN", np.round(corr_matrix, 2))  # Annotiamo i NaN come tali

    # Creazione del grafico
    plt.figure(figsize=(15, 10))
    sns.heatmap(
        corr_matrix_display,
        annot=annotations,  # Mostra le annotazioni (inclusi i "NaN")
        cmap='coolwarm',
        vmin=-1,
        vmax=1,
        fmt='',  # Mostra il testo così com'è
        xticklabels=df.columns,
        yticklabels=df.columns
    )
    plt.title(title)
    plt.show()

    return corr_matrix


def correlation_matrix(df, title):
    # Escludiamo l'ultima colonna
    df = df.iloc[:, :-1]  # Escludiamo l'ultima colonna

    n = df.shape[1]
    corr_matrix = np.zeros((n, n))  # Inizializziamo la matrice delle correlazioni

    # Iteriamo su tutte le coppie di colonne
    for i in range(n):
        for j in range(i, n):  # Include anche (i, i) per la diagonale
            if np.all(df.iloc[:, i] == df.iloc[:, i][0]) or np.all(df.iloc[:, j] == df.iloc[:, j][0]):
                # Se una delle colonne è costante (valori tutti uguali), la correlazione non è definita
                corr_matrix[i, j] = corr_matrix[j, i] = np.nan
            else:
                # Calcolo della correlazione di Spearman
                corr, _ = stats.spearmanr(df.iloc[:, i], df.iloc[:, j], nan_policy='omit')
                corr_matrix[i, j] = corr_matrix[j, i] = corr

    # Gestione dei NaN per garantire la visibilità nel grafico
    corr_matrix_display = np.where(np.isnan(corr_matrix), 0, corr_matrix)  # Sostituiamo NaN con 0 per il grafico
    annotations = np.where(np.isnan(corr_matrix), "NaN", np.round(corr_matrix, 2))  # Annotiamo i NaN come tali

    # Creazione del grafico
    plt.figure(figsize=(15, 10))
    sns.heatmap(
        corr_matrix_display,
        annot=annotations,  # Mostra le annotazioni (inclusi i "NaN")
        cmap='coolwarm',
        vmin=-1,
        vmax=1,
        fmt='',  # Mostra il testo così com'è
        xticklabels=df.columns,
        yticklabels=df.columns
    )
    plt.title(title)
    plt.show()

    return corr_matrix

"""**Correlazione emozioni**"""

corr_greedy_emotion = correlation_matrix(llama_greedy[emotions].astype(float), 'Correlation Matrix for LLama GREEDY Emotions')

"""Questa matrice di correlazione mostra le relazioni presenti fra le emozioni come appaiono nel testo. Per esempio, vediamo che `joy` e "optimism" sono fortemente correlate (0.69), il che significa che nei testi emozionalmente positivi queste due emozioni tendono a comparire insieme. Allo stesso modo, c’è una relazione tra "sadness" e "fear" (0.43), il che suggerisce che contenuti più cupi o negativi riflettono queste emozioni in parallelo. Ci sono anche relazioni negative significative: ad esempio, "joy" e "anger" sono inversamente correlate (-0.29), il che ha senso, dato che emozioni opposte raramente convivono nello stesso contesto. Anche "optimism" e "anger" mostrano una relazione negativa (-0.38), evidenziando come l'ottimismo diminuisca in presenza della rabbia. Alcune emozioni, come "surprise", mostrano correlazioni più basse con le altre, indicando che sono più autonome e meno legate alle altre emozioni."""

corr_greedy_neutral_emotion = correlation_matrix_neutral(llama_greedy_neutral[emotions].astype(float), 'Correlation Matrix for LLama GREEDY NEUTRAL Emotions')

"""L'introduzione dell'attributo `no emotion` ha un impatto significativo sull'analisi. La presenza della neutralità rivela una maggiore complessità nelle relazioni tra le emozioni, sfidando la visione semplificata di emozioni polarizzate tra positivo e negativo. Le correlazioni tra le emozioni "pure" possono attenuarsi leggermente, indicando che parte della loro varianza è ora spiegata dalla relazione con la neutralità. Questa nuova dimensione ci permette di esplorare aspetti più sottili delle esperienze emotive umane, come l'intensità delle emozioni e l'influenza di fattori esterni."""

corr_top_k_emotion = correlation_matrix(llama_top_k[emotions].astype(float), 'Correlation Matrix for LLama TOP K Emotions')

corr_top_k_neutral_emotion = correlation_matrix_neutral(llama_top_k_neutral[emotions].astype(float), 'Correlation Matrix for LLama TOP K NEUTRAL Emotions')

corr_top_p_emotion = correlation_matrix(llama_top_p[emotions].astype(float), 'Correlation Matrix for LLama TOP P Emotions')

corr_top_p_neutral_emotion = correlation_matrix_neutral(llama_top_p_neutral[emotions].astype(float), 'Correlation Matrix for LLama TOP P NEUTRAL Emotions')

"""Le matrici di correlazione evidenziano una chiara separazione tra emozioni positive e negative, mostrando come queste tendano a raggrupparsi rispettivamente in cluster distinti. Emozioni come gioia, fiducia e ottimismo sono frequentemente correlate tra loro. Allo stesso modo, tristezza, rabbia, pessimismo e paura mostrano correlazioni, formando un gruppo emotivo negativo. Ciò suggerisce che le emozioni di una stessa polarità tendono a rafforzarsi reciprocamente, mentre quelle di polarità opposta raramente coesistono.

Un aspetto interessante è che le correlazioni tra emozioni positive e negative risultano spesso basse o negative, segnalando una netta distinzione tra i due gruppi. Questo fenomeno può essere spiegato dalla natura contrastante degli stati emotivi che rappresentano: le emozioni positive sono legate a situazioni di approccio, crescita o soddisfazione, mentre quelle negative sono tipicamente connesse a risposte di difesa, paura o perdita. Nei testi, questa distinzione si traduce in una coerenza emotiva che raramente mescola emozioni opposte.

Tuttavia, alcune emozioni come la sorpresa potrebbero rappresentare un’eccezione, fungendo da ponte tra stati positivi e negativi a seconda del contesto in cui si manifestano. Questa ambivalenza sottolinea che, sebbene la separazione sia predominante, non tutte le emozioni si conformano rigidamente a questa divisione.

**Correlazione Tratti Morali**
"""

corr_greedy_moral = correlation_matrix(llama_greedy[moral_traits].astype(float), 'Correlation Matrix for LLama GREEDY Moral Traits')

"""Si noti che nel caso dei tratti morale la correlazione fra gli elementi si mantiene abbastanza elevata."""

corr_greedy_neutral_moral = correlation_matrix_neutral(llama_greedy_neutral[moral_traits].astype(float), 'Correlation Matrix for LLama GREEDY NEUTRAL Moral traits')

"""La seconda matrice introduce un nuovo attributo, "no moral", che rappresenta l'assenza o la neutralità rispetto a un giudizio morale. L'introduzione di "no moral" modifica leggermente l'intensità di alcune correlazioni tra i tratti "puri", ma la struttura generale rimane simile."""

corr_top_k_moral = correlation_matrix(llama_top_k[moral_traits].astype(float), 'Correlation Matrix for LLama TOP K Moral Traits')

corr_top_k_neutral_moral = correlation_matrix_neutral(llama_top_k_neutral[moral_traits].astype(float), 'Correlation Matrix for LLama TOP K NEUTRAL Moral Traits')

corr_top_p_moral = correlation_matrix(llama_top_p[moral_traits].astype(float), 'Correlation Matrix for LLama TOP P Moral traits')

corr_top_p_neutral_moral = correlation_matrix_neutral(llama_top_p_neutral[moral_traits].astype(float), 'Correlation Matrix for LLama TOP P NEUTRAL Moral traits')

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

def correlation_comparison(correlations, labels):
    # Verifica che la lista di correlazioni non sia vuota
    if len(correlations) == 0:
        raise ValueError("La lista delle correlazioni non può essere vuota.")

    # Assumiamo che la prima matrice di correlazione abbia le etichette delle emozioni
    # Se le matrici sono numpy.ndarray, le converto in pandas DataFrame per utilizzare 'columns'
    if isinstance(correlations[0], np.ndarray):
        # Creiamo il DataFrame usando le dimensioni della matrice e le etichette predefinite
        emotion_labels = [f"{labels[i]}" for i in range(correlations[0].shape[0])]
        correlations = [pd.DataFrame(corr, columns=emotion_labels, index=emotion_labels) for corr in correlations]
    else:
        emotion_labels = correlations[0].columns  # Se già DataFrame, usiamo le colonne

    # Calcoliamo la matrice di correlazione media
    average_corr = np.mean([corr.values for corr in correlations], axis=0)
    average_corr = pd.DataFrame(average_corr, columns=emotion_labels, index=emotion_labels)

    # Calcoliamo la matrice delle differenze medie assolute
    diff_matrix = np.mean([np.abs(corr.values - average_corr.values) for corr in correlations], axis=0)
    diff_matrix = pd.DataFrame(diff_matrix, columns=emotion_labels, index=emotion_labels)

    # Visualizza la matrice di correlazione media
    plt.figure(figsize=(10, 8))
    sns.heatmap(average_corr, annot=True, cmap='coolwarm', center=0, fmt=".2f",
                xticklabels=emotion_labels, yticklabels=emotion_labels)
    plt.title("Average Correlation Matrix")
    plt.show()

    # Visualizza la heatmap delle differenze medie assolute
    plt.figure(figsize=(10, 8))
    sns.heatmap(diff_matrix, annot=True, cmap='coolwarm', center=0, fmt=".2f",
                xticklabels=emotion_labels, yticklabels=emotion_labels)
    plt.title("Mean Absolute Differences Matrix")
    plt.show()

"""**Confronto correlazione emozioni**

Per una analisi più approfondita sui vari metodi di decoding scelti si è deciso di creare le seguenti matrici di confronto:

- **Average Correlation Matrix**, si osservano i valori medi di correlazione tra ciascuna coppia di emozioni, che variano da -1 (correlazione negativa perfetta) a +1 (correlazione positiva perfetta). I toni rossi più accesi rappresentano correlazioni positive più forti, mentre le tonalità di blu indicano correlazioni negative.

- **Mean Absolute Differences Matrix**, invece, esplora le differenze medie assolute tra le emozioni, offrendo una prospettiva complementare. Qui i valori rappresentano la magnitudine media delle discrepanze tra le emozioni, senza tener conto della direzione (positiva o negativa). I colori rossi più intensi evidenziano coppie di emozioni che differiscono in modo più marcato.

L'interpretazione congiunta delle due matrici consente di delineare un quadro più completo delle relazioni tra emozioni. Le coppie di emozioni con alte correlazioni positive nella prima matrice tendono ad avere differenze medie basse nella seconda, suggerendo somiglianze strutturali nei dati. Al contrario, correlazioni negative elevate si accompagnano spesso a differenze maggiori.
"""

#Confronto modelli senza neutrale
correlations = [corr_greedy_emotion, corr_top_k_emotion, corr_top_p_emotion]
correlation_comparison(correlations, emotions)

#Confronto modelli con neutrale
correlations = [corr_greedy_neutral_emotion, corr_top_k_neutral_emotion, corr_top_p_neutral_emotion]
correlation_comparison(correlations, emotions)

"""**Confronto correlazione tratti morali**"""

#Confronto modelli senza neutrale
correlations = [corr_greedy_moral, corr_top_k_moral, corr_top_p_moral]
correlation_comparison(correlations, moral_traits)

#Confronto modelli con neutrale
correlations = [corr_greedy_neutral_moral, corr_top_k_neutral_moral, corr_top_p_neutral_moral]
correlation_comparison(correlations, moral_traits)

"""Dall'analisi congiunta delle **Average Correlation Matrices** e delle **Mean Absolute Differences Matrices** emergono osservazioni significative sulle relazioni tra le emozioni e i tratti morali nei dati analizzati. Le correlazioni positive forti, come quelle tra *Optimism* e *Joy* o tra *Care* e *Loyalty*, indicano una chiara coesistenza di queste emozioni nei testi, suggerendo che il modello tende a riconoscerle insieme in contesti simili. Questo potrebbe riflettere una sovrapposizione semantica o una connessione logica tra queste categorie emozionali. Al contrario, le correlazioni negative, come quelle osservate tra *Anger* e *Joy* o tra *Fear* e *Optimism*, evidenziano una relazione opposta, dove la presenza di un'emozione esclude quella dell'altra, in linea con la loro natura intrinseca.

Le **Mean Absolute Differences Matrices** arricchiscono l'interpretazione, evidenziando quanto divergono in media gli score assegnati a ciascuna coppia di emozioni. Coppie con alte correlazioni positive, come *Care* e *Loyalty*, mostrano differenze medie basse, confermando una forte affinità nei dati. Al contrario, emozioni opposte, come *Anger* e *Joy*, presentano differenze medie più elevate, riflettendo la loro separazione concettuale.

Questa doppia prospettiva permette di delineare un quadro più completo delle relazioni tra emozioni: da un lato, le correlazioni mostrano i legami diretti tra le emozioni, mentre le differenze medie offrono un’indicazione sulla variabilità degli score. In sintesi, il modello evidenzia una buona capacità di riconoscere la coesistenza o la contrapposizione di emozioni nei testi, suggerendo una comprensione strutturata delle dinamiche emozionali, utile per analisi approfondite delle narrazioni mediali.

### **2.1.3 Qual è il rapporto tra le emozioni neutrali e le emozioni esplicite?**

In generale, è considerato più semplice rilevare la presenza di emozioni rispetto alla loro assenza, poiché le emozioni spesso si manifestano attraverso segnali espliciti, come cambiamenti nel linguaggio, nel comportamento o nel contesto. L'assenza di emozioni, invece, può essere più sottile e difficile da identificare, poiché si basa su una percezione implicita di neutralità piuttosto che su segnali distintivi. Questo concetto trova supporto nella psicologia, dove è noto che il nostro cervello tende a focalizzarsi maggiormente sugli stimoli emotivi rispetto agli stati neutri. Tale problematica è stata affrontata da (et al. A. V. Kolmogorova) in cui si evidenzia la difficoltà nel recuperare *dataset* contenenti testi che risuktino neutrali. Questo perché dai testi condivisi su intenret scaturiscono sempre delle emozioni **[9]**.  Ciò potrebbe inserire all'interno del LLM dei *bias* che portino ad una difficoltà da parte dei modelli nel rilevare l'assenza di emozioni.

In questa analisi, l'obiettivo è esplorare la correlazione tra emozioni "neutrali" (o tratti morali neutrali) e le altre emozioni rilevate nei testi. La neutralità è intesa come una condizione in cui non sono presenti emozioni specifiche, e il suo studio aiuta a comprendere meglio come il modello attribuisca questa categoria rispetto alle altre emozioni.

Per una più facile visualizzazione sono stati riportati dei grafici che descrivono la correlazione tra `no_emotion` (e `no_moral_trait`) e le altre emozioni (o tratti morali).
"""

import pandas as pd
import matplotlib.pyplot as plt

def analyze_neutral_correlation(dfs, neutral_string, names, aspect_to_analyze = "Emotions"):
    """
    Calculates the Spearman correlation between the 'Neutral' emotion and all other emotions
    in different DataFrames and visualizes the results.
    """
    # Dictionary to store correlations for plotting
    correlations = {}

    for i, df in enumerate(dfs):
        # Calcola la matrice di correlazione di Spearman
        spearman_corr = df.corr(method='spearman')

        # Ottieni le correlazioni con la colonna 'neutral_string' e rimuovi 'neutral_string' stesso
        corr_with_neutral = spearman_corr.loc[neutral_string].drop(neutral_string)

        # Aggiungi al dizionario
        correlations[f'{names[i]}'] = corr_with_neutral

    # Convert correlations dictionary to DataFrame for easier plotting
    correlations_df = pd.DataFrame(correlations)

    # Plotting
    plt.figure(figsize=(12, 8))
    correlations_df.plot(kind='bar', figsize=(12, 8), colormap="viridis", edgecolor='black')
    plt.title(f"Spearman Correlations of 'Neutral' with Other {aspect_to_analyze} Across Runs")
    plt.xlabel("Emotion")
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.ylabel("Correlation with 'Neutral'")
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()
    plt.show()

names = ['Greedy', 'Top K', 'Top P']
analyze_neutral_correlation(dfs_moral_trait_neutral_models, 'no moral', names, "Moral Traits")
analyze_neutral_correlation(dfs_emotion_neutral_models, 'no emotion', names)

"""Dal grafico emerge che la correlazione tra la categoria "Neutral" e gli altri tratti o emozioni è prevalentemente negativa, indicando che un'elevata rilevazione di neutralità è spesso associata a una minore presenza di emozioni o tratti morali specifici. Ciò ad indicare che il modello compensa l'assenza di determinate emozioni con un valore neutrale. Questo fenomeno è particolarmente evidente nella configurazione *Greedy* (nel grafico dei tratti morali), dove le correlazioni negative sono più pronunciate, suggerendo che questo metodo considera `no_moral_trait` in maniera più esclusiva rispetto agli altri tratti, portando a un maggiore contrasto. Al contrario, sempre considerando il grafico dei tratti morali, le configurazioni *Top K* e *Top P* risultano meno rigide: alcune correlazioni sono meno negative o addirittura leggermente positive per tratti come *Loyalty* o *Subversion*. Ciò indica una maggiore capacità di queste configurazioni di cogliere una coesistenza tra la neutralità e alcuni tratti morali, dimostrando una flessibilità che manca in *Greedy*. Inoltre, tratti più concreti, come *Care* e *Harm*, tendono a mostrare correlazioni più negative rispetto a concetti morali più astratti, come *Authority* o *Loyalty*, suggerendo che la neutralità è percepita in modo più polarizzato quando si tratta di tratti morali diretti.

Nel caso in cui consideriamo il grafico delle emozioni, invece, a comportarsi in maniera più rigida risulta essere il modello con metodo di *decoding* Top-k in quanto questo presenta le correlazioni negative più basse.

Ancora una volta è possibile concludere che il tipo di configurazione inflenza di molto i risultati delle annotazioni.
"""

import matplotlib.pyplot as plt
import numpy as np

def compare_scores_horizontal(df_with_neutral, df_without_neutral, emotions):
    """
    Compare scores between datasets using horizontal grouped bar plots

    Parameters:
    - df_with_neutral: DataFrame containing neutral category scores
    - df_without_neutral: DataFrame without neutral categories
    - emotions: List of emotions/traits to compare
    """

    # Validate datasets
    assert len(df_with_neutral) == len(df_without_neutral), "Datasets must have equal length"
    assert all(df_with_neutral.index == df_without_neutral.index), "Datasets must have same indices"

    n_texts = len(df_with_neutral)
    indices = np.arange(n_texts)  # 0-based indices
    bar_height = 0.35  # Height of individual bars

    for emotion in emotions:
        plt.figure(figsize=(12, 38))

        # Get scores from both datasets
        scores_with = df_with_neutral[emotion].values
        scores_without = df_without_neutral[emotion].values

        # Create horizontal bars
        plt.barh(indices - bar_height/2, scores_with,
                 height=bar_height, label='With neutral', alpha=0.8)
        plt.barh(indices + bar_height/2, scores_without,
                 height=bar_height, label='Without neutral', alpha=0.8)

        # Customize plot
        plt.title(f"Score Comparison for '{emotion}'")
        plt.xlabel("Score Value")
        plt.ylabel("Text Index")
        plt.yticks(indices, indices + 1)  # Show 1-based text indices
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(axis='x', alpha=0.3)

        # Set dynamic ylim based on number of texts
        plt.ylim(-bar_height, n_texts - 1 + bar_height)
        plt.tight_layout()
        plt.show()

compare_scores_horizontal(llama_greedy_neutral, llama_greedy, emotions)
compare_scores_horizontal(llama_greedy_neutral, llama_greedy, moral_traits)

compare_scores_horizontal(llama_top_k_neutral, llama_top_k, emotions)
compare_scores_horizontal(llama_top_k_neutral, llama_top_k, moral_traits)

compare_scores_horizontal(llama_top_p_neutral, llama_top_p, emotions)
compare_scores_horizontal(llama_top_p_neutral, llama_top_p, moral_traits)

"""Nel caso del modello Llama, la configurazione greedy mostra una tendenza a mantenere gli score delle emozioni o tratti morali invariati, indipendentemente dalla presenza dell'opzione "no:_motion" o "no_moral". Tuttavia, si osservano casi in cui emozioni con score molto alti (ad esempio superiori a 0.8) vengono azzerati quando viene introdotta la possibilità di considerare emozioni o tratti morali neutrali.
In altri casi, alcune emozioni risultano presenti solo quando viene presa in considerazione l'opzione neutrale. Inoltre, ci sono situazioni in cui gli score delle emozioni aumentano quando si include la neutralità.

Passando alla configurazione top-k, il comportamento del modello migliora rispetto al greedy. Nella maggior parte dei casi, gli score diminuiscono o vengono azzerati quando si considera la neutralità. Tuttavia, permangono alcune anomalie in cui gli score aumentano in presenza di neutralità.

La configurazione top-p, invece, rappresenta un buon compromesso tra i metodi di decoding. Nella maggior parte dei casi, gli score diminuiscono o si azzerano quando si introduce la neutralità, anche se si osservano alcune anomalie, ma in misura minore rispetto alle altre configurazioni.

### **2.1.4 Distibutions**

L'analisi delle distribuzioni delle emozioni offre una visione complessiva di come il modello rilevi e attribuisca le diverse emozioni nei testi. Capire come queste emozioni si distribuiscono è fondamentale per valutare la capacità del modello di cogliere la complessità emotiva, identificando eventuali squilibri o tendenze predominanti. Ad esempio, una distribuzione equilibrata potrebbe indicare che il modello è in grado di riconoscere una varietà di emozioni senza favorirne alcune a scapito di altre. Al contrario, una distribuzione sbilanciata potrebbe suggerire difficoltà nel rilevare determinate emozioni o una sovrastima di altre, influenzando l'accuratezza delle annotazioni.

Inoltre, le distribuzioni permettono di individuare emozioni sottorappresentate o sovrarappresentate, fornendo indizi sul comportamento del modello e sul tipo di segnali che tende a privilegiare. Questo tipo di analisi diventa particolarmente utile quando si confrontano configurazioni diverse del modello (ad esempio *Greedy*, *Top K*, *Top P*) o quando si valutano specifiche categorie come emozioni neutre o intense.

L'analisi si suddivide, per ogni gruppo di risultati, nel verificare in quanti testi le emozioni (o tratti morali) risultano essere presenti (o assenti) e le distribuzioni degli score che vengono assegnati.
"""

import math
import matplotlib.pyplot as plt

def emotion_distribution_across_texts(df, title):

    # Number of emotions
    num_emotions = len(df.columns[:])

    # Determine the grid size for subplots
    cols = 4
    rows = math.ceil(num_emotions / cols)

    fig, axes = plt.subplots(rows, cols, figsize=(15, rows * 5))
    axes = axes.flatten()

    for i, emotion in enumerate(df.columns):
        # Count the number of texts where the emotion is present (> 0)
        emotion_presence = (df[emotion] > 0).astype(int)  # Convert to binary (1 if present, 0 otherwise)

        # Check if the emotion is present in any text
        if emotion_presence.sum() == 0:
            # Hide the subplot if the emotion is not present in any text
            axes[i].set_visible(False)
        else:
            # Plot the distribution of emotion presence across texts
            axes[i].hist(emotion_presence, bins=2, color='skyblue', edgecolor='black', align='left')
            axes[i].set_title(f"{emotion} Distribution Across Texts")
            axes[i].set_xlabel('Emotion Presence (0: Absent, 1: Present)')
            axes[i].set_ylabel('Number of Texts')

    # Remove any unused subplots
    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])


    plt.tight_layout()
    plt.suptitle(title, y=1.02, fontsize=16)
    plt.show()

def emotion_distribution(df, title):
    num_emotions = len(df.columns[:])
    cols = 4
    rows = math.ceil(num_emotions / cols)

    # Create subplots
    fig, axes = plt.subplots(rows, cols, figsize=(15, rows * 5))
    axes = axes.flatten()

    for i, emotion in enumerate(df.columns[1:]):
        # Convert emotion values to float and drop NaN values
        emotion_values = df[emotion].astype(float).dropna()

        # Check if the column has non-zero values to plot
        if emotion_values[emotion_values != 0].empty:
            axes[i].set_visible(False)
        else:
            axes[i].hist(emotion_values[emotion_values != 0], bins=10, color='skyblue', edgecolor='black')
            axes[i].set_title(f"{emotion} Distribution")
            axes[i].set_xlabel('Scores')
            axes[i].set_ylabel('Frequency')

    # Remove any unused subplots
    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.suptitle(title, y=1.02, fontsize=16)
    plt.show()

emotion_distribution_across_texts(llama_greedy_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait greedy decoding")

emotion_distribution(llama_greedy_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait greedy decoding")

emotion_distribution_across_texts(llama_greedy[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait greedy decoding without Neutral")

emotion_distribution(llama_greedy[columns[6:28]], "Distribution for Each Emotion and Moral Trait greedy decoding without Neutral")

emotion_distribution_across_texts(llama_top_k_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-k decoding")

emotion_distribution(llama_top_k_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait top K decoding")

emotion_distribution_across_texts(llama_top_k[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-k decoding without Neutral")

emotion_distribution(llama_top_k[columns[6:28]], "Distribution for Each Emotion and Moral Trait top K decoding without Neutral")

emotion_distribution_across_texts(llama_top_p_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-p decoding")

emotion_distribution(llama_top_p_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait top P decoding")

emotion_distribution_across_texts(llama_top_p[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-p decoding")

emotion_distribution(llama_top_p[columns[6:28]], "Distribution for Each Emotion and Moral Trait top P decoding without Neutral")

"""Analizziamo entrmabi i tipi di distribuzioni:

1. **Distribuzione delle emozioni nei testi**: dall'analisi dei grafici è possiibile notare come il *greedy decoding* tenda a rilvae poche emozioni (o tratti morali) in quanto, per la maggior parte di loro prevale l'assenza nei testi rispetto alla loro presenza. Unica eccezione si ha nel caso in cui si analizza l'emozione (o tratto morale) neutrale. Ciò a conferma della poca "esplorazione" applicata da questa modalità di decodifica nell'analisi delle emozioni contenuti nei testi. Per gli altri due metodi di decoding la distribuzione nei testi delle diverse emozioni sembra, anche se di poco, più bilanciata. Ci sono alcune emozioni per cui tutti i modelli hanno lo stesso comportamento: primo tra tutti dell'emozione "neutrale" prevale sempre la presenza piuttosto che l'assenza; emozioni come paura, amore, tristezza pessimism, disgusto sono assenti nella maggior parte dei testi. Ciò potrebbe essere indicativo del fatto che nel *dataset* analizzato siano pochi i testi in cui si individuano tali emozioni. Infine, con le strategie di decoding Top-p e Top-k l'emozione di ottimismo e `fairness` risualtano essere molto frequenti all'interno dei testi contrastando i risultati del *greedy decoding*.

2. **Distribuzione degli score delle mozioni**: la decodifica *greedy* mostra una tendenza all'assegnazione dei punteggi "bipolare". Con ciò si intende l'alternarsi dell'assegnazione di un punteggio molto alto o molto basso per ogni emozione con poche eccezioni. Cio indica la tendenza da parte di questa decodifica nel fare scelte estremamente determinate e meno flessibili, privilegiando punteggi che enfatizzano categorie molto marcate a discapito di sfumature più deboli o intermedie.. Gli score invece assegnati dalle modalità di decoding Top-k o Top-p risultano essere più diversificate non mostrando però alcun andamento particolare.

### **2.1.5 Entropia**
Per analizzare in maniera più approfondita le distribuzioni dei pesi assegnati alle emozioni (o tratti morali), si è deciso di calcolarne l'entropia. Questa misura è in grado di quantificare il grado di diversità con cui i tre algoritmi di decoding assegnano gli score. Un valore di entropia più alto indica una distribuzione più diversificata, mentre un valore più basso riflette una tendenza verso distribuzioni più bilanciate.
"""

import pandas as pd
from scipy.stats import entropy

def create_entropy_table(results, names, emotion_columns, moral_trait_columns):

    statistics = []

    for df, name in zip(results, names):
        # Calcolo delle probabilità per emozioni e tratti morali
        emotion_probabilities = df[emotion_columns].mean() / df[emotion_columns].mean().sum()
        moral_trait_probabilities = df[moral_trait_columns].mean() / df[moral_trait_columns].mean().sum()

        # Calcolo dell'entropia
        emotion_entropy = entropy(emotion_probabilities, base=2)  # Entropia delle emozioni (in bit)
        moral_trait_entropy = entropy(moral_trait_probabilities, base=2)  # Entropia dei tratti morali (in bit)

        # Aggiunta delle statistiche
        statistics.append({
            'Dataset': name,
            'Emotion Entropy': emotion_entropy,
            'Moral Trait Entropy': moral_trait_entropy
        })

    # Converti in DataFrame
    stats_df = pd.DataFrame(statistics).set_index('Dataset')

    return stats_df

names = ['Greedy', 'Greedy Neutral', 'Top K', 'Top K Neutral', 'Top P', 'Top P Neutral']
dfs = [llama_greedy, llama_greedy_neutral, llama_top_k, llama_top_k_neutral,llama_top_p, llama_top_p_neutral]
entropies = create_entropy_table(dfs, names, emotions, moral_traits)
entropies

"""Dai risultati sopra riportati nella tabella emerge che le configurazioni *Greedy* mostrano i valori di entropia più bassi in entrambe le dimensioni analizzate, sia per le emozioni che per i tratti morali. Questo risultato indica una tendenza del modello, con questa modalità di decoding, a generare distribuzioni meno diversificate, privilegiando poche emozioni o tratti morali con punteggi predominanti, a discapito di una maggiore varietà. Tale comportamento riflette la natura deterministica di *Greedy Decoding*, che esplora meno possibilità rispetto ad approcci più probabilistici.

Al contrario, le configurazioni *Top K* e *Top P* presentano valori di entropia più elevati, evidenziando una maggiore capacità di rappresentare distribuzioni più bilanciate e diversificate. In particolare, l’aggiunta della modalità *Neutral* in queste configurazioni porta a un ulteriore incremento dell’entropia, suggerendo che il modello riesca a catturare una gamma più ampia di emozioni o tratti morali, evitando di concentrare i punteggi su poche categorie. Ad esempio, *Top P Neutral* e *Top K Neutral* si distinguono per i valori di entropia più alti, sottolineando la loro flessibilità nell'annotare emozioni e tratti morali con maggiore ricchezza di dettagli.

Un altro aspetto interessante è che, in generale, i tratti morali mostrano entropie leggermente più alte rispetto alle emozioni in tutte le configurazioni. Questo potrebbe indicare che i tratti morali, nel dataset analizzato, hanno una distribuzione intrinsecamente più variegata oppure che il modello è meno incline a polarizzarli rispetto alle emozioni.

Poiché lo scopo del progetto è l'annotazione, e quindi, l'individuazione delle diverse emozioni contenute all'interno di un testo si è ritenuto più adatto il comportamento dei modelli che utilizzano la decodifica Top-p i quali considerano anche la possibilità di analizzare emozioni (o tratti morali) neutrali.

### **2.1.6 Comparison Positive and Negative Emotions/Moral Traits**

In ultima istanza è stata condotta una analisi sulla predominanza di emozioni positive o negative per verificare quale delle due classi di emozioni prevale secondo i diversi algoritmi di *decding*.
"""

import matplotlib.pyplot as plt

def compare_positive_negative_emotions(df, positive_emotions, negative_emotions, title):

    # Calculate the total score for positive emotions
    positive_total = df[positive_emotions].astype(float).sum().sum()

    # Calculate the total score for negative emotions
    negative_total = df[negative_emotions].astype(float).sum().sum()

    # Calculate the grand total
    grand_total = positive_total + negative_total

    # Calculate percentages
    positive_percentage = (positive_total / grand_total) * 100 if grand_total > 0 else 0
    negative_percentage = (negative_total / grand_total) * 100 if grand_total > 0 else 0

    categories = ['Positive Emotions', 'Negative Emotions']
    percentages = [positive_percentage, negative_percentage]

    plt.figure(figsize=(10, 6))
    bars = plt.bar(categories, percentages, color=['green', 'red'])
    plt.title(title)
    plt.xlabel('Emotion Categories')
    plt.ylabel('Percentage (%)')

    # Display the values on the bars
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval, f"{round(yval, 2)}%", va='bottom', ha='center')

    plt.show()

# Positive emotions
positive_emotions = ['anticipation', 'trust', 'joy',
    'optimism', 'surprise', 'love'
]

# Negative emotions
negative_emotions = ['disgust', 'anger', 'sadness',
    'pessimism', 'fear'
]

compare_positive_negative_emotions(llama_greedy, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions GREEDY")

compare_positive_negative_emotions(llama_greedy_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions GREEDY NEUTRAL")

compare_positive_negative_emotions(llama_top_k, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP K")

compare_positive_negative_emotions(llama_top_k_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP K NEUTRAL")

compare_positive_negative_emotions(llama_top_p, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP P")

compare_positive_negative_emotions(llama_top_p_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP P NEUTRAL")

"""**Confronto tratti morali positivi e negativi**"""

import matplotlib.pyplot as plt

def compare_positive_negative_moral_traits(df, positive_traits, negative_traits, title):
    # Calcoliamo il punteggio totale per i tratti morali positivi
    positive_total = df[positive_traits].astype(float).sum().sum()

    # Calcoliamo il punteggio totale per i tratti morali negativi
    negative_total = df[negative_traits].astype(float).sum().sum()

    # Calcoliamo il totale complessivo
    grand_total = positive_total + negative_total

    # Calcoliamo le percentuali
    positive_percentage = (positive_total / grand_total) * 100 if grand_total > 0 else 0
    negative_percentage = (negative_total / grand_total) * 100 if grand_total > 0 else 0

    categories = ['Positive Moral Traits', 'Negative Moral Traits']
    percentages = [positive_percentage, negative_percentage]

    plt.figure(figsize=(10, 6))
    bars = plt.bar(categories, percentages, color=['green', 'red'])
    plt.title(title)
    plt.xlabel('Moral Traits Categories')
    plt.ylabel('Percentage (%)')

    # Visualizzazione dei valori sopra le barre
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval, f"{round(yval, 2)}%", va='bottom', ha='center')

    plt.show()

# Lista dei tratti morali positivi
positive_traits = ['care_scores', 'fairness_scores', 'loyalty_scores', 'authority_scores','purity_scores']

# Lista dei tratti morali negativi
negative_traits = ['harm_scores', 'cheating_scores', 'betrayal_scores', 'subversion_scores','degradation_scores']

compare_positive_negative_moral_traits(llama_greedy, positive_traits, negative_traits, "Comparison Between Positive and Negative Moral traits GREEDY")

compare_positive_negative_moral_traits(llama_greedy_neutral, positive_traits, negative_traits, "Comparison Between Positive and Negative Moral traits GREEDY NEUTRAL")

compare_positive_negative_moral_traits(llama_top_k, positive_traits, negative_traits, "Comparison Between Positive and Negative Moral traits TOP_K")

compare_positive_negative_moral_traits(llama_top_k_neutral, positive_traits, negative_traits, "Comparison Between Positive and Negative Moral traits TOP_K NEUTRAL")

compare_positive_negative_moral_traits(llama_top_p, positive_traits, negative_traits, "Comparison Between Positive and Negative Moral traits TOP_P")

"""Da tale studio emerge che vi è una percentuale maggiore, seppur non di molto, di emozioni positive rispetto quelle negative, così come di tratti morali positivi rispetto quelli negativi.

La predominanza di emozioni positive potrebbe riflettere una tendenza nei dati analizzati, che potrebbe derivare dalla natura stessa del contenuto. Ciò potrebbe indicare una tendenza nei testi generati dagli utenti a esprimere emozioni maggiormente positive in contesti pubblici. Lo stesso vale per quanto riguarda i tratti morali. Inoltre, tali risultati potrebbero anche derivare da come il modello crea le annotazioni, in particolare le categorie morali positive potrebbero essere rappresentate meglio. Altra considerazione da dover tenere in conto è il sampling casuale dei 200 articoli selezionati i quali potrebbero essere, per gli argomenti trattati, più inclini a contenere temi e linguaggi con connotazioni positive o che enfatizzano tratti morali positivi. Questa selezione potrebbe dunque introdurre un bias nei risultati, riflettendo una rappresentazione non completamente bilanciata dei dati.

## **2.2 Conclusioni per Llama 3.1**
Dalle analisi effettuate possiamo concludere che il modello Meta LLaMA 3.1, analizzato nel contesto dell'annotazione di emozioni e tratti morali in notizie dell'HuffPost, si distingue per la sua flessibilità nelle diverse configurazioni di *decoding* (*Greedy*, Top-k e Top-p) e per la capacità di rilevare sfumature emotive e morali nei testi. Le analisi hanno evidenziato come le modalità di decoding più esplorative, come Top-k e Top-p, siano in grado di annotare un numero maggiore di emozioni e tratti morali, mostrando una maggiore diversificazione rispetto al metodo *Greedy*.

Un punto cruciale emerso dallo studio riguarda l'influenza della classe "Neutral": la sua introduzione aumenta significativamente il numero di annotazioni generali, a scapito della diversificazione delle emozioni e dei tratti morali rilevati. Questo suggerisce una propensione del modello a identificare neutralità in assenza di segnali emotivi o morali distintivi, soprattutto con configurazioni come la *Greedy*.

Le correlazioni tra emozioni e tratti morali, calcolate tramite l'analisi delle distribuzioni e delle matrici di correlazione, rivelano che il modello percepisce relazioni significative tra determinate categorie, ma mostra anche limitazioni nella coerenza delle annotazioni, soprattutto nei casi più complessi. La modalità Top-p emerge come la più bilanciata per identificare emozioni e tratti morali senza sovrastimare la neutralità.

Vi è da sottolineare anche una distribuzione sbilanciata tra le emozioni (o tratti morali) positivi e negativi. Tale sbilanciamento si presenta anche nel momento in cui si analizzano le singole classi di emozioni (o tratti morali). Ciò potrebbe causare una sfida per l'annotazione automatica delle emozioni da parte del modello.

In sintesi, Meta LLaMA 3.1 dimostra un buon potenziale per l'annotazione automatica di emozioni e valori morali, specialmente con configurazioni più esplorative, ma richiede ulteriori ottimizzazioni per migliorare la coerenza e ridurre eventuali bias introdotti dall'inclusione della categoria "Neutral". Questi risultati offrono indicazioni utili per sviluppi futuri e per l'adozione del modello in contesti applicativi specifici.

# **3. Mistral**

Il modello Mistral **[10]** è una rete neurale avanzata, progettata per l'elaborazione del linguaggio naturale (NLP), che si distingue per le sue capacità di comprensione contestuale e generazione del testo.

**Caratteristiche principali di Mistral**
1. **Architettura avanzata**: Mistral utilizza un'architettura transformer ottimizzata che consente un'elevata efficienza computazionale.
2. **Capacità di contestualizzazione**: Grazie alla sua struttura, il modello è in grado di analizzare il significato di una parola o frase nel contesto più ampio del testo.
3. **Miglior gestione delle sequenze lunghe**: Rispetto ad altri modelli, Mistral è in grado di processare testi più estesi mantenendo alta la coerenza e la precisione delle analisi.

L'annotazione automatizzata delle emozioni e dei tratti morali nei testi è un compito complesso che richiede una comprensione approfondita del linguaggio e delle sfumature semantiche. Mistral si rivela un alleato prezioso in questo ambito.
Quindi, il modello Mistral rappresenta un potente strumento per l'annotazione di emozioni e tratti morali nei testi, offrendo un equilibrio tra efficienza, precisione e adattabilità. Il suo utilizzo può facilitare ricerche linguistiche, analisi sociologiche e applicazioni nel campo dell'intelligenza artificiale etica.
"""

import torch
from transformers import pipeline
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

# Configuration for 8-bit quantization to reduce model size and speed up inference
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
)

# Loading the tokenizer associated with the Mistral model
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-v0.1")


mistral_id = "mistralai/Mistral-7B-Instruct-v0.1"
# Loading the 4-bit quantized Mistral model with device placement automatically assigned
mistral_8bit = AutoModelForCausalLM.from_pretrained(
    mistral_id,
    device_map="auto",  # Automatically map model layers to available devices
    quantization_config=quantization_config,  # Apply the previously defined quantization configuration
)

"""La versione che è stata caricata del modello Mistral è caratterizzata dalla quantizzazione a 8 bit, necessario per ridurre la grandezza del modello andandone a diminuire, di conseguenza la complessità computazionale.
Si noti che i prompt utilizzati sono specificati nell'appendice A del notebook.

"""

mistral_emotions_evaluations_df = generate_emotion_morality_dataset(df, mistral_id, mistral_8bit, tokenizer, prompt_morality_mistral, prompt_emotions_mistral, generation_params_greedy, columns, len(df))
mistral_emotions_evaluations_df

"""La descrizione dei metodi utilizzati è fornita dettagliatamente nei paragrafi precedenti.


"""

nan_counter(mistral_top_k)

import csv
#saving mistral df
mistral_emotion_evaluations_df.to_csv('df_mistral_results_top_p.csv', index=False, quoting=csv.QUOTE_ALL)

import pandas as pd
import csv
mistral_top_k = pd.read_csv('/content/df_mistral_results_top_k.csv')
mistral_top_k_neutral = pd.read_csv('/content/df_mistral_results_top_k_neutral.csv')
mistral_greedy = pd.read_csv('/content/df_mistral_results_greedy.csv')
mistral_greedy_neutral = pd.read_csv('/content/df_mistral_results_greedy_neutral.csv')
mistral_top_p = pd.read_csv('/content/df_mistral_results_top_p.csv')
mistral_top_p_neutral = pd.read_csv('/content/df_mistral_results_top_p_neutral.csv')

"""## 3.1 Mistral result analysis

### **3.1.1 Statistiche dei risultati di Mistral**
"""

dfs_mistral = [mistral_greedy, mistral_greedy_neutral, mistral_top_k, mistral_top_k_neutral, mistral_top_p, mistral_top_p_neutral]
dfs_names_mistral = ["mistral Greedy", "mistral Greedy Neutral", "mistral Top K", "mistral Top K Neutral", "mistral Top P", "mistral Top P Neutral"]
stats_for_mistral = create_table_of_statistics(dfs_mistral, dfs_names_mistral , tokenizer, emotions, moral_traits)
stats_for_mistral

"""Dall'analisi dei risultati si nota come:
*   Nel caso in cui non si utilizza il campo 'Neutral' il modello con la tecnica di decoding Greedy individua meno tratti morali rispetto le tecniche Top-k e Top-p.

*   Nel caso in cui si introduce il campo 'Neutral', al contrario, il modello con la tecnica di decoding Greedy individua più tratti morali rispetto le tecniche Top-k e Top-p, ciò potrebbe essere dovuto a due fattori:

  1. Un aumento dell'individuazione da parte del modello di più tratti morali.
  2. Come nel caso del modello Llama, una tendenza eccessiva dell'assegnazione del tratto morale `no_moral` alla maggior parte dei testi.

Prendendo in considerazione le emozioni, invece, si ha la stessa tendenza riscontrata con il modello LLama, ovvero: il metodo di decoding Top-p risulta trovare più emozioni rispetto agli altri modelli.

Anche mistral usa come modalità di tokenizzazione la *BPE* **[11]** come il modello Llama. Il numero medio ti *token* rilevati risulta essere però maggiore a causa delle modifiche effettuate al *prompt*. Le modifiche sono specificate nell'Appendice A.


"""

moral_trait_tables_mistral = create_moral_traits_count_tables(dfs_mistral, dfs_names_mistral, moral_traits)
print(moral_trait_tables_mistral.to_string())

"""Si nota come l'aggiunta del campo 'Neutral' nelle varie configurazioni vari la frequenza della classe no_moral, in particolare nel caso Greedy aumenta del 9.34%, nel caso Top-k del 11.68% e nella configurazione Top-p del 9.85%.

I tartti morali hanno una frequenza simile fra essi che varia da 8% al 12% circa e che diminuisce con l'introduzione del campo 'Neutral'. La modalità Neutral risulta utile per identificare testi privi di moralità, a scapito di una riduzione nella granularità delle annotazioni dei tratti morali presenti.
Il tratto no_neutral viene riconosciuto nella maggior parte dei testi, contribuendo in modo consistente all'incremento complessivo delle annotazioni medie per testo. Questa osservazione suggerisce che il modello, quando configurato per includere la classe "neutrale", tende a classificare un numero maggiore di testi come contenenti tratti morali, sebbene ciò possa ridurre la presenza delle altre categorie. Pertanto, il comportamento del modello con l'opzione "neutrale" evidenzia una predisposizione a rilevare la presenza di moralità generica piuttosto che distinguere in modo preciso i tratti morali specifici.


"""

emotion_tables_mistral = create_emotions_count_tables(dfs_mistral, dfs_names_mistral, emotions)
print(emotion_tables_mistral.to_string())

"""Anche nel caso delle emozioni, si ha un comportamento simile allo studio dei tratti morali. In particolare, le configurazioni senza "Neutral" tendono a rilevare un numero maggiore di emozioni specifiche.

"Joy" è l'emozione rilevata più frequentemente, "Disgust" e "Fear" quelle rilevate meno frequentemente.

Al contrario, l'aggiunta della modalità "Neutral" porta a una riduzione della rilevazione di emozioni specifiche, con un aumento della classe No Emotion, che raggiunge la percentuale di 11.88% in Top P Neutral. Questo indica che il modello, con l'opzione "Neutral", diventa più cauto nel rilevare emozioni, attribuendo una maggiore neutralità ai testi.

Come per il caso dei tratti morali, anche per l'annotazione delle emozioni, l'aumento del numero medio delle emozioni rilevate è dovuto ad un aumento della rilevazione dell'emozioni no_emotions .

Per una più facile visualizzazione dei dati appena descritti sono stati creati due metodi per la rappresentazione graTca dei risultati.
"""

emotion_occurrence(mistral_greedy, 'Emotion Distribution (Greedy Decoding, No Neutral)', emotions)
emotion_occurrence(mistral_greedy_neutral, 'Emotion Distribution (Greedy Decoding)', emotions)

emotion_occurrence(mistral_greedy, 'Moral Traits Distribution (Greedy Decoding, No Neutral)', moral_traits)
emotion_occurrence(mistral_greedy_neutral, 'Moral Traits Distribution (Greedy Decoding)', moral_traits)

"""Dal grafico relativo al Greedy Decoding si può notare una leggera diminuzione nella rilevazione delle emozioni nel momento in cui viene inserita la possibilità di considerare delle emozioni (o tratti morali) neutrali.

In LLAMA 3.1 la diminuzione era più drastica rispetto Mistral, quindi l'introduzione della neutralità aveva un effetto maggiore.

"""

emotion_occurrence(mistral_top_k, 'Emotion Distribution (Top K = 50, No Neutral)', emotions)
emotion_occurrence(mistral_top_k_neutral, 'Emotion Distribution (Top K = 50)', emotions)

emotion_occurrence(mistral_top_k, 'Moral Trait Distribution (Top K = 50, No Neutral)', moral_traits)
emotion_occurrence(mistral_top_k_neutral, 'Moral Trait Distribution (Top K = 50)', moral_traits)

"""Per la configurazione di decoding Top-k la diminuzione delle occorrenze delle emozioni specifiche rispetto alle neutrali risulta essere leggermente più marcata."""

emotion_occurrence(mistral_top_p, 'Emotion Distribution (Top P)', emotions)
emotion_occurrence(mistral_top_p_neutral, 'Emotion Distribution (Top P)', emotions)

emotion_occurrence(mistral_top_p, 'Moral Trait Distribution (Top P)', moral_traits)
emotion_occurrence(mistral_top_p_neutral, 'Moral Trait Distribution (Top P)', moral_traits)

"""Anche nel caso del Top-p sampling, la riduzione delle occorrenze delle emozioni specifiche rispetto a quelle neutrali risulta poco significativa.

Successivamente sono stati effettuati dei confronti grafici che tengono conto sia delle diverse configurazioni di decoding sia della presenza o meno dell'elemento neutrale all'interno delle classi di emozioni che si vogliono annotare.
"""

#comparing two distribution at a time for neutral and non neutral run
dfs_moral_trait_mistral_greedy = [mistral_greedy[moral_traits].astype(float), mistral_greedy_neutral[moral_traits].astype(float)]
dfs_moral_trait_mistral_top_k = [mistral_top_k[moral_traits].astype(float),mistral_top_k_neutral[moral_traits].astype(float)]
dfs_moral_trait_mistral_top_p = [mistral_top_p[moral_traits].astype(float),mistral_top_p_neutral[moral_traits].astype(float)]

#comparing all non neutral run
dfs_moral_trait_all_models = [mistral_greedy[moral_traits].astype(float),mistral_top_k[moral_traits].astype(float),mistral_top_p[moral_traits].astype(float) ]

#comparing all neutral run
dfs_moral_trait_neutral_models = [mistral_greedy_neutral[moral_traits].astype(float),mistral_top_k_neutral[moral_traits].astype(float),mistral_top_p_neutral[moral_traits].astype(float) ]

#greedy comparison
labels = ['Greedy (No Neutral)', 'Greedy']
comparison_emotion_occurrences(dfs_moral_trait_mistral_greedy, labels, "Moral Traits Distribution Comparison Greedy")


#top k comparison
labels = ['Top K (No Neutral)', 'Top K']
comparison_emotion_occurrences(dfs_moral_trait_mistral_top_k, labels, "Moral Traits Distribution Comparison Top K = 50")

#top p comparison
labels = ['Top P (No Neutral)', 'Top P']
comparison_emotion_occurrences(dfs_moral_trait_mistral_top_p, labels, "Moral Traits Distribution Comparison Top P")

#comparison all non neutral model
labels = ['Greedy', 'Top K', 'Top P']
comparison_emotion_occurrences(dfs_moral_trait_all_models, labels, "Moral Traits Distribution Comparison All Models")

#comparison all neutral model
labels = ['Greedy Neutral', 'Top K Neutral', 'Top P Neutral']
comparison_emotion_occurrences(dfs_moral_trait_neutral_models, labels, "Moral Traits Distribution Comparison All Neutral Models")

"""Dal confronto grafico si può evincere che il metodo di decoding che è in grado di individuare meno tratti morali risulta essere top-k. Il metodo di decoding Greedy individua più tratti morali del metodo Top-p sia nel caso in cui i tratti morali neutrali vengono considerate che nel caso opposto.

Tali risultati risultano essere in contrasto con i risultati forniti da LLAMA 3.1 in cui modelli con decoding Top p e Top k erano quelli in grado di individuare più tratti morali.
"""

# Comparing two distributions at a time for neutral and non-neutral run
dfs_emotion_mistral_greedy = [mistral_greedy[emotions].astype(float), mistral_greedy_neutral[emotions].astype(float)]
dfs_emotion_mistral_top_k = [mistral_top_k[emotions].astype(float), mistral_top_k_neutral[emotions].astype(float)]
dfs_emotion_mistral_top_p = [mistral_top_p[emotions].astype(float), mistral_top_p_neutral[emotions].astype(float)]

# Comparing all non-neutral runs
dfs_emotion_all_models = [mistral_greedy[emotions].astype(float), mistral_top_k[emotions].astype(float), mistral_top_p[emotions].astype(float)]

# Comparing all neutral runs
dfs_emotion_neutral_models = [mistral_greedy_neutral[emotions].astype(float), mistral_top_k_neutral[emotions].astype(float), mistral_top_p_neutral[emotions].astype(float)]

# Greedy comparison
labels = ['Greedy (No Neutral)', 'Greedy']
comparison_emotion_occurrences(dfs_emotion_mistral_greedy, labels, "Emotions Distribution Comparison Greedy")

# Top K comparison
labels = ['Top K (No Neutral)', 'Top K']
comparison_emotion_occurrences(dfs_emotion_mistral_top_k, labels, "Emotions Distribution Comparison Top K = 50")

# Top P comparison
labels = ['Top P (No Neutral)', 'Top P']
comparison_emotion_occurrences(dfs_emotion_mistral_top_p, labels, "Emotions Distribution Comparison Top P")

# Comparison all non-neutral models
labels = ['Greedy', 'Top K', 'Top P']
comparison_emotion_occurrences(dfs_emotion_all_models, labels, "Emotions Distribution Comparison All Models")

# Comparison all neutral models
labels = ['Greedy Neutral', 'Top K Neutral', 'Top P Neutral']
comparison_emotion_occurrences(dfs_emotion_neutral_models, labels, "Emotions Distribution Comparison All Neutral Models")

"""Il numero di annotazioni maggiori nel caso in cui non si considera l'emozione *no_emotion* è ottenuto dalle emozioni joy e optimism con valori che si aggirano intorno al 160. Seguite poi da emozioni come:
anticipation, trust, love, anger e sadness con valori che si aggirano intorno alle 130. Si può notare, inoltre, che a seconda della strategia di decoding utilizzata vi è una netta variazione tra l'occorrenza delle diverse emozioni all'interno dei testi. In particolare, il metodo di decoding top-k sembra riuscire ad annotare più emozioni rispetto agli altri. Il modello che meno riesce a trovare emozioni è il greedy, ciò a causa del suo determinismo.

Con l'aggiunta dell'emozione neutrale vi è un picco di annotazioni di no_emotion che superano addirittura le 175 occorrenze. Sia inoltre una variazione nelle altre emozioni  che risultano essere annotate meno frequentemente riducendo così il numero di occorrenze rilevate. Anche in questo caso la configurazione **greedy* è quella che trova meno emozioni e Top-p quella che ne trova di più, battendo top-k rispetto al caso precedente.


La differenza nel numero di annotazioni mostra come l'introduzione della neutralità introduce un cambiamento significativo nel comportamento del modello in quanto i valori delle annotazioni variano drasticamente.

### **3.1.2 Analisi della correlazione**
Anche per Mistral viene studiata la correlzione di Spearman, come fatto per il modello LLAMA 3.1.

L'analisi della matrice di correlazione fornirà, quindi, una base quantitativa per riflettere sulle capacità degli LLM nel catturare sfumature emotive e morali, aiutandoci a delineare il potenziale e le criticità di questi strumenti nel campo del linguaggio naturale.

**Correlazione Emozioni**
"""

corr_greedy_emotion = correlation_matrix(mistral_greedy[emotions].astype(float), 'Correlation Matrix for mistral GREEDY Emotions')
corr_greedy_neutral_emotion = correlation_matrix_neutral(mistral_greedy_neutral[emotions].astype(float), 'Correlation Matrix for mistral GREEDY NEUTRAL Emotions')

"""La prima matrice di correlazione mostra le relazioni presenti fra le emozioni come appaiono nel testo. Per esempio, vediamo che "love" e "optimism" sono fortemente correlate (0.93) così come "optimism" e "joy" (0.93), il che significa che nei testi emozionalmente positivi queste due emozioni tendono a comparire insieme. Allo stesso modo, c'è una forte relazione tra "disgust" e "fear" (0.97), il che suggerisce che contenuti più cupi o negativi riaettono queste emozioni in parallelo.

La presenza della neutralità rivela una maggiore complessità nelle relazioni tra le emozioni. Le correlazioni tra le emozioni "pure" possono attenuarsi leggermente, indicando che parte della loro varianza è ora spiegata dalla relazione con la neutralità. Questa nuova dimensione ci permette di esplorare aspetti più sottili delle esperienze emotive umane, come l'intensità delle emozioni e l'inauenza di fattori esterni.
"""

corr_top_k_emotion = correlation_matrix(mistral_top_k[emotions].astype(float), 'Correlation Matrix for mistral TOP K Emotions')
corr_top_k_neutral_emotion = correlation_matrix_neutral(mistral_top_k_neutral[emotions].astype(float), 'Correlation Matrix for mistral TOP K NEUTRAL Emotions')

corr_top_p_emotion = correlation_matrix(mistral_top_p[emotions].astype(float), 'Correlation Matrix for mistral TOP P Emotions')
corr_top_p_neutral_emotion = correlation_matrix_neutral(mistral_top_p_neutral[emotions].astype(float), 'Correlation Matrix for mistral TOP P NEUTRAL Emotions')

"""Si noti come con le tecniche Top p sampling e Top k sampling, i valori di coorrelazione risultano essere meno forti.

**Correlazione Tratti Morali**

Di seguito sono mostrati gli stessi studi ma per i tratti morali
"""

corr_greedy_moral = correlation_matrix(mistral_greedy[moral_traits].astype(float), 'Correlation Matrix for mistral GREEDY Moral Traits')
corr_greedy_neutral_moral = correlation_matrix_neutral(mistral_greedy_neutral[moral_traits].astype(float), 'Correlation Matrix for mistral GREEDY NEUTRAL Moral traits')

corr_top_k_moral = correlation_matrix(mistral_top_k[moral_traits].astype(float), 'Correlation Matrix for mistral TOP K Moral Traits')
corr_top_k_neutral_moral = correlation_matrix_neutral(mistral_top_k_neutral[moral_traits].astype(float), 'Correlation Matrix for mistral TOP K NEUTRAL Moral Traits')

corr_top_p_moral = correlation_matrix(mistral_top_p[moral_traits].astype(float), 'Correlation Matrix for mistral TOP P Moral traits')
corr_top_p_neutral_moral = correlation_matrix_neutral(mistral_top_p_neutral[moral_traits].astype(float), 'Correlation Matrix for mistral TOP P NEUTRAL Moral traits')

"""Di seguito viene mostrata la visualizzazione della matrice di correlazione media (ottenuta facendo la media dei valori di correlazione delle diverse matrici ottenute per le emozioni o tratti morali) e una matrice di correlazione che mostra le differenze assolute tra i vari punteggi di correlazione. L'interpretazione congiunta delle due matrici consente di delineare un quadro più completo delle relazioni tra emozioni. Le coppie di emozioni con alte correlazioni positive nella prima matrice tendono ad avere differenze medie basse nella seconda, suggerendo somiglianze strutturali nei dati. Al contrario, correlazioni negative elevate si accompagnano spesso a differenze maggiori."""

#Confronto modelli senza neutrale
correlations = [corr_greedy_emotion, corr_top_k_emotion, corr_top_p_emotion]
correlation_comparison(correlations, emotions)
#Confronto modelli con neutrale
correlations = [corr_greedy_neutral_emotion, corr_top_k_neutral_emotion, corr_top_p_neutral_emotion]
correlation_comparison(correlations, emotions)

#Confronto modelli senza neutrale
correlations = [corr_greedy_moral, corr_top_k_moral, corr_top_p_moral]
correlation_comparison(correlations, moral_traits)
#Confronto modelli con neutrale
correlations = [corr_greedy_neutral_moral, corr_top_k_neutral_moral, corr_top_p_neutral_moral]
correlation_comparison(correlations, moral_traits)

"""Dall'analisi congiunta delle Average Correlation Matrices e delle Mean Absolute Differences Matrices emergono osservazioni significative sulle relazioni tra le emozioni e i tratti morali nei dati analizzati. Le correlazioni positive forti, come quelle tra Optimism e Joy o tra Trust e Love, indicano una chiara coesistenza di queste emozioni nei testi, suggerendo che il modello tende a riconoscerle insieme in contesti simili. Questo potrebbe riflettere una sovrapposizione semantica o una connessione logica tra queste categorie emozionali.

Le Mean Absolute Differences Matrices arricchiscono l'interpretazione, evidenziando quanto divergono in media gli score assegnati a ciascuna coppia di emozioni.
Si noti, però, come il LLAMA 3.1 le differenze medie risultavano essere meno evidenti indicando una maggiore concordanza fra gli score assegnati dalle varie configurazioni.

### **3.1.3 Qual è il rapporto tra le emozioni neutrali e le emozioni esplicite?**
"""

names = ['Greedy', 'Top K', 'Top P']
analyze_neutral_correlation(dfs_moral_trait_neutral_models, 'no moral', names, "Moral Traits")
analyze_neutral_correlation(dfs_emotion_neutral_models, 'no emotion', names)

"""Dai grafici emerge che la correlazione tra la categoria "Neutral" e gli altri tratti o emozioni è quasi esclusivamente positiva, a differenza da ciò che avveniva con LLAMA 3.1. Questo effetto risulta particolarmente evidente nella configurazione Greedy, dove le correlazioni sono più marcate rispetto a Top-K e Top-P. La correlazioni tra le emozioni (o tratti morali) con la configurazione **greedy* hanno una correlazione positiva pari a 0.7.

Nel grafico relativo ai tratti morali, si nota come "Neutral" sia fortemente associato a concetti come cheating, loyalty e purity, specialmente con la strategia Greedy. Questo suggerisce che il modello, in questa configurazione, potrebbe enfatizzare maggiormente alcune dimensioni morali rispetto ad altre.  

Nel grafico relativo alle emozioni emergono correlazioni particolarmente elevate con stati affettivi positivi come trust, joy e optimism, mentre emozioni come fear mostrano valori molto bassi o quasi nulli. Anche in questo caso, Greedy tende ad amplificare queste associazioni rispetto alle altre configurazioni.  

Rispetto a LLAMA 3.1, la mancanza di correlazioni negative e la forte associazione con alcuni tratti ed emozioni specifiche potrebbero indicare che la rappresentazione della categoria "Neutral" nel modello attuale sia meno bilanciata o più polarizzata. Questo potrebbe avere implicazioni sulle risposte generate, rendendole meno sfumate e più inclinate verso determinate dimensioni morali o emotive.
"""

compare_scores_horizontal(mistral_greedy_neutral, mistral_greedy, emotions)
compare_scores_horizontal(mistral_greedy_neutral, mistral_greedy, moral_traits)

compare_scores_horizontal(mistral_top_k_neutral, mistral_top_k, emotions)
compare_scores_horizontal(mistral_top_k_neutral, mistral_top_k, moral_traits)

compare_scores_horizontal(mistral_top_p_neutral, mistral_top_p, emotions)
compare_scores_horizontal(mistral_top_p_neutral, mistral_top_p, moral_traits)

"""Per quanto riguarda il modello Mistral, la configurazione greedy presenta un comportamento simile a quello di Llama, con gli score che tendono a rimanere invariati. Tuttavia, Mistral mostra più anomalie rispetto a Llama, con un aumento degli score in presenza di neutralità, suggerendo una minore capacità di identificare correttamente la neutralità.

Con la configurazione top-k, il modello si comporta meglio rispetto al greedy, ma meno efficacemente rispetto a Llama. Si osservano più casi in cui gli score aumentano anziché diminuire, indicando una difficoltà nel gestire la neutralità.

La configurazione top-p si conferma come la scelta migliore anche per Mistral, con un comportamento più stabile nella gestione della neutralità, sebbene presenti più casi di assegnazione anomala degli score rispetto a Llama.

### **3.1.4 Distibuzioni**
"""

emotion_distribution_across_texts(mistral_greedy_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait greedy decoding")
emotion_distribution(mistral_greedy_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait greedy decoding")

emotion_distribution_across_texts(mistral_greedy[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait greedy decoding without Neutral")
emotion_distribution(mistral_greedy[columns[6:28]], "Distribution for Each Emotion and Moral Trait greedy decoding without Neutral")

emotion_distribution_across_texts(mistral_top_k_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-k decoding")
emotion_distribution(mistral_top_k_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait top K decoding")

emotion_distribution_across_texts(mistral_top_k[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-k decoding without Neutral")
emotion_distribution(mistral_top_k[columns[6:28]], "Distribution for Each Emotion and Moral Trait top K decoding without Neutral")

emotion_distribution_across_texts(mistral_top_p_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-p decoding")
emotion_distribution(mistral_top_p_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait top P decoding")

emotion_distribution_across_texts(mistral_top_p[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-p decoding")
emotion_distribution(mistral_top_p[columns[6:28]], "Distribution for Each Emotion and Moral Trait top P decoding without Neutral")

"""Analizziamo entrmabi i tipi di distribuzioni:
1. **Distribuzione delle emozioni e tratti morali nei testi**: dall'analisi dei grafici si può notare come in tutte le tecniche di decoding, la presenza di emozioni o tratti morali sia più ricorrente rispetto l'assenza.
Ci sono alcune emozioni per cui tutti i modelli hanno lo stesso comportamento: primo tra tutti dell'emozione "neutrale" prevale sempre la presenza piuttosto che l'assenza; emozioni come paura, disgusto, tristezza pessimismo sono assenti nella maggior parte dei testi. Ciò potrebbe essere indicativo del fatto che nel dataset analizzato siano pochi i testi in cui si individuano tali emozioni.
2.**Distribuzione degli score delle emozioni e tratti morali**: la decodifica greedy mostra una assegnazione di score con valori intermedi, ovvero nè troppo elevati nè troppo bassi mostrando una distribuzione degli score abbastanza uniforme senza picchi significativi. Gli score invece assegnati dalla modalità di decoding Top-k tendono ad avere picchi per score intermedi (0.5, 0.6) ad indicare una tendenza del modello a non sbilanciarsi troppo in questa configurazione di decoding su valori polarizzanti troppo bassi o troppo alti. Gli score assegnati da Top-p risultano essere più diversificate senza mostrare alcun andamento particolare proprio come nel caso della configurazione *greedy*.

### **3.1.5 Entropia**
"""

names = ['Greedy', 'Greedy Neutral', 'Top K', 'Top K Neutral', 'Top P', 'Top P Neutral']
dfs = [mistral_greedy, mistral_greedy_neutral, mistral_top_k, mistral_top_k_neutral, mistral_top_p, mistral_top_p_neutral]
entropies = create_entropy_table(dfs, names, emotions, moral_traits)
entropies

"""I risultati mostrano l'entropia media delle emozioni e dei tratti morali per diversi metodi di generazione del modello. L'entropia più alta indica che il modello distribuisce gli score in modo più uniforme tra le diverse emozioni o i tratti morali, mentre un valore più basso suggerisce una maggiore concentrazione su pochi elementi.

Si osserva che la configurazione **Greedy Neutral** ha l'entropia più alta per entrambi gli aspetti, suggerendo che questa variante genera testi con una distribuzione di emozioni e tratti morali più ampia e meno polarizzata. Questo potrebbe indicare una maggiore diversità nella classificazione delle emozioni rispetto alla variante standard **Greedy**, che mostra una tendenza leggermente più focalizzata.

**Top-K** e **Top-P** hanno entropie leggermente inferiori rispetto a **Greedy Neutral**, suggerendo che questi metodi di generazione portano a distribuzioni più concentrate, con il modello che assegna score più nettamente a determinate emozioni o tratti morali. Tra i due, **Top-P** ha l'entropia più bassa, il che indica una maggiore selettività nella distribuzione degli score rispetto a **Top-K**.

Le versioni **Neutral** per ogni metodo mostrano sistematicamente un aumento dell'entropia, il che suggerisce che questa configurazione contribuisce a una distribuzione più bilanciata e meno polarizzata degli score assegnati. Questo potrebbe essere dovuto a un effetto di riduzione dell'influenza di emozioni o tratti dominanti, permettendo una valutazione più omogenea delle diverse categorie.

### **3.1.6 Comparison Positive and Negative Emotions/Moral Traits**
"""

compare_positive_negative_emotions(mistral_greedy, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions GREEDY")
compare_positive_negative_emotions(mistral_greedy_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions GREEDY NEUTRAL")
compare_positive_negative_emotions(mistral_top_k, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP K")
compare_positive_negative_emotions(mistral_top_k_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP K NEUTRAL")
compare_positive_negative_emotions(mistral_top_p, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP P")
compare_positive_negative_emotions(mistral_top_p_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP P NEUTRAL")

"""Lo studio evidenzia una prevalenza di emozioni e tratti morali positivi rispetto a quelli negativi. La predominanza di emozioni positive potrebbe riflettere una tendenza insita nei dati analizzati, influenzata dalla natura del contenuto. Questo potrebbe indicare che i testi generati dagli utenti tendono a esprimere più frequentemente emozioni positive, soprattutto in contesti pubblici. Una dinamica simile si osserva anche nei tratti morali, dove le categorie positive potrebbero essere rappresentate in modo più marcato, forse anche a causa del modo in cui il modello assegna le annotazioni.  

Un ulteriore aspetto da considerare è la selezione casuale dei 200 articoli analizzati, che potrebbe aver influenzato i risultati. Se i temi trattati negli articoli fossero maggiormente orientati verso un linguaggio e contenuti con connotazioni positive, ciò potrebbe aver introdotto un bias, portando a una rappresentazione non completamente equilibrata della distribuzione di emozioni e tratti morali.

## **3.2 Conclusioni per Mistral**

Il modello Mistral si è dimostrato particolarmente efficace nel rilevamento di emozioni e tratti morali, soprattutto in configurazioni che favoriscono l'esplorazione come il Top-p e Top-k sampling. Nonostante le sue prestazioni siano generalmente elevate, il modello ha evidenziato una tendenza a sovrastimare le emozioni neutrali quando questa classe era inclusa, riducendo la varietà complessiva delle annotazioni. In configurazioni prive della modalità "Neutral", il modello ha offerto una rappresentazione più diversificata e dettagliata, rendendolo una scelta preferibile per analisi approfondite.

# **4. Gemma 2**

Gemma è una famiglia di modelli di intelligenza artificiale open-source sviluppata da Google DeepMind, progettata per offrire prestazioni avanzate in elaborazione del linguaggio naturale rimanendo, allo stesso tempo, leggera ed efficiente. Disponibile in diverse dimensioni, tra cui 2 miliardi (2B), 9 miliardi (9B) e 27 miliardi (27B) di parametri **[12]**, Gemma 2 è ottimizzata per un'inferenza ultraveloce su una vasta gamma di hardware, rendendola accessibile sia per sviluppatori che per ricercatori.

In termini di prestazioni, il modello Gemma 2 da 27B parametri ha rapidamente scalato la classifica di LMSYS Chatbot Arena, superando modelli popolari di dimensioni più che doppie in conversazioni reali e coinvolgenti, affermandosi come uno dei modelli open source più utili e di alto livello.

Dunque, Gemma 2 rappresenta un nuovo standard per i modelli di intelligenza artificiale open source, combinando prestazioni di alto livello con un'ampia accessibilità e facilità d'uso, aprendo nuove possibilità per applicazioni avanzate nel campo dell'IA.
"""

import torch
import os
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

# Load pre-trained model and tokenizer
model_id_gemma = "google/gemma-2-9b-it"
lora_config = BitsAndBytesConfig(
    load_in_8bit=True,
)

tokenizer_gemma = AutoTokenizer.from_pretrained(model_id_gemma)
gemma = AutoModelForCausalLM.from_pretrained(model_id_gemma, quantization_config=lora_config, device_map="auto")

gemma_emotions_evaluations_df = generate_emotion_morality_dataset(df, model_id_gemma, gemma, tokenizer_gemma, prompt_morality, prompt_emotions, generation_params_greedy, columns)

nan_counter(gemma_top_k)

import csv
#saving mistral df
gemma_emotion_evaluations_df.to_csv('df_mistral_results_top_k_neutral.csv', index=False, quoting=csv.QUOTE_ALL)

import pandas as pd
import csv
gemma_top_k = pd.read_csv('/content/df_gemma_results_top_k.csv')
gemma_top_k_neutral = pd.read_csv('/content/df_gemma_results_top_k_neutral.csv')
gemma_greedy = pd.read_csv('/content/df_gemma_results_greedy.csv')
gemma_greedy_neutral = pd.read_csv('/content/df_gemma_results_greedy_neutral.csv')
gemma_top_p = pd.read_csv('/content/df_gemma_results_top_p.csv')
gemma_top_p_neutral = pd.read_csv('/content/df_gemma_results_top_p_neutral.csv')

"""## **4.1 Gemma 2 Result Analysis**

### **4.1.1 Statistiche dei risultati di Gemma**
"""

dfs_gemma = [gemma_greedy, gemma_greedy_neutral, gemma_top_k, gemma_top_k_neutral, gemma_top_p, gemma_top_p_neutral]
dfs_names_gemma = ["Gemma Greedy", "Gemma Greedy Neutral", "Gemma Top K", "Gemma Top K Neutral", "Gemma Top P", "Gemma Top P Neutral"]
stats_for_gemma = create_table_of_statistics(dfs_gemma, dfs_names_gemma , tokenizer_gemma, emotions, moral_traits)
stats_for_gemma

"""Dall'analisi dei risultati presentati in tabella emerge che il numero medio di emozioni e tratti morali rilevati varia leggermente tra le diverse configurazioni: il metodo **Greedy** si dimostra più conservativo, producendo un numero inferiore di annotazioni (5.8 emozioni e 4.49 tratti morali) rispetto ai metodi più esplorativi come **Top-k** e **Top-p**, che raggiungono valori più elevati (fino a 6.57 emozioni e 5.37 tratti morali nella configurazione **Top-p Neutral**).  

L'introduzione della modalità **Neutral** in ciascun approccio incrementa leggermente la ricchezza delle annotazioni, suggerendo che questa configurazione possa favorire una maggiore sensibilità del modello nel rilevare dettagli emotivi e morali nei testi. In generale, i metodi **Top-k** e **Top-p** sembrano fornire annotazioni più ricche rispetto a **Greedy**, rendendoli più adatti per applicazioni che richiedono un livello di granularità maggiore. Tuttavia, resta da verificare se l'aumento del numero di annotazioni corrisponda effettivamente a una maggiore accuratezza e coerenza rispetto ai dati di riferimento.  

La metodologia di tokenizzazione usata da Gemma 2 è la stessa che per il modello precedente ovvero: SentencePiece **[13]**. SentencePiece è un metodo per selezionare token da una lista precompilata, ottimizzando il processo di tokenizzazione in base a un corpus fornito. Questo approccio è utile per gestire sottoparole e migliorare la tokenizzazione nei modelli linguistici. Tale metodologia si può basare sia su Unigram che su BPE, tutto dipende dalle specifiche definite durante la fase di addestramento del modello **[14]**.
"""

moral_trait_tables_gemma = create_moral_traits_count_tables(dfs_gemma, dfs_names_gemma, moral_traits)
print(moral_trait_tables_gemma.to_string())

"""Si osserva che l'introduzione della modalità **"Neutrale"** in tutte le configurazioni aumenta, come ci si aspettava, la frequenza della classe **no_moral** del 14% circa, diminuendo di conseguenza la rilevazione degli altri tratti morali.

Tra i tratti morali, **Care** risulta essere il più frequentemente identificato. D'altra parte, tratti come **Betrayal**, **Cheating** e  **Purity** sono tra i meno annotati, suggerendo una possibile difficoltà del modello nel riconoscerli o una loro minore rappresentazione nei dati analizzati.  

Osservando la tabella relativa al numero medio di tratti morali rilevati dal modello, si nota che, per ogni configurazione, l'aggiunta dell'opzione **Neutral** porta a un aumento del numero medio di tratti morali annotati. Questo fenomeno è spiegabile dal fatto che il tratto **no_moral** viene riconosciuto nella maggior parte dei testi, contribuendo in modo consistente all'incremento complessivo delle annotazioni medie per testo.  

"""

emotion_tables_gemma = create_emotions_count_tables(dfs_gemma, dfs_names_gemma, emotions)
print(emotion_tables_gemma.to_string())

"""Dai dati analizzati emerge che le configurazioni senza **"Neutral"** tendono a rilevare un numero maggiore di emozioni specifiche. In particolare, **Optimism** (Ottimismo) e **Trust** (Fiducia) risultano tra le emozioni più frequentemente annotate. Al contrario, l'aggiunta della modalità **"Neutral"** porta a una riduzione della rilevazione di emozioni specifiche, con un aumento significativo della classe **No Emotion**, che raggiunge il **12,18%** nella configurazione **Gemma Greedy Neutral**.

Analogamente a quanto osservato per i tratti morali, anche nel caso delle emozioni, l'aumento del numero medio di emozioni rilevate è dovuto principalmente a un incremento drastico della rilevazione della classe **No Emotion**.  

Per facilitare la visualizzazione e l'interpretazione dei dati, sono stati sviluppati due metodi dedicati alla rappresentazione grafica dei risultati, che consentono di analizzare in modo immediato le tendenze e le differenze tra le varie configurazioni.  

"""

emotion_occurrence(gemma_greedy, 'Emotion Distribution (Greedy Decoding, No Neutral)', emotions)
emotion_occurrence(gemma_greedy_neutral, 'Emotion Distribution (Greedy Decoding)', emotions)

emotion_occurrence(gemma_greedy, 'Moral Traits Distribution (Greedy Decoding, No Neutral)', moral_traits)
emotion_occurrence(gemma_greedy_neutral, 'Moral Traits Distribution (Greedy Decoding)', moral_traits)

emotion_occurrence(gemma_top_k, 'Emotion Distribution (Top K = 50, No Neutral)', emotions)
emotion_occurrence(gemma_top_k_neutral, 'Emotion Distribution (Top K = 50)', emotions)

emotion_occurrence(gemma_top_k, 'Moral Trait Distribution (Top K = 50, No Neutral)', moral_traits)
emotion_occurrence(gemma_top_k_neutral, 'Moral Trait Distribution (Top K = 50)', moral_traits)

emotion_occurrence(gemma_top_p, 'Emotion Distribution (Top P)', emotions)
emotion_occurrence(gemma_top_p_neutral, 'Emotion Distribution (Top P)', emotions)

emotion_occurrence(gemma_top_p, 'Moral Trait Distribution (Top P)', moral_traits)
emotion_occurrence(gemma_top_p_neutral, 'Moral Trait Distribution (Top P)', moral_traits)

"""I grafici precedenti mostrano la distribuzione delle emozioni e dei tratti morali rilevati. In tutte le configurazioni relative alle emozioni "disgust" e "fear" sono le emozioni meno rilevate, al contrario di "optimism" la quale appare molto spesso.
Per quanto riguarda i tratti morali si nota che gli score "cheating score" e "purity score" sono fra i meno rilevati, al contrario di "care scores"

È evidente come nei grafici in cui si considera la modalità Neutral, vi sia una diminuzione poco significativa della presenza delle altre emozioni/tratti morali. Ciò ad indicare come il modello abbia difficoltà a scindere la neutralità delle emozioni (o tratti morali) da quelle specifiche. Ciò porta a una coesistenza di emozioni e neutralità.

Successivamente sono stati effettuati dei confronti grafici che tengono conto sia delle diverse configurazioni di decoding sia della presenza o meno dell'elemento neutrale all'interno delle classi di emozioni che si vogliono annotare.
"""

#comparing two distribution at a time for neutral and non neutral run
dfs_moral_trait_gemma_greedy = [gemma_greedy[moral_traits].astype(float), gemma_greedy_neutral[moral_traits].astype(float)]
dfs_moral_trait_gemma_top_k = [gemma_top_k[moral_traits].astype(float),gemma_top_k_neutral[moral_traits].astype(float)]
dfs_moral_trait_gemma_top_p = [gemma_top_p[moral_traits].astype(float),gemma_top_p_neutral[moral_traits].astype(float)]

#comparing all non neutral run
dfs_moral_trait_all_models = [gemma_greedy[moral_traits].astype(float),gemma_top_k[moral_traits].astype(float),gemma_top_p[moral_traits].astype(float) ]

#comparing all neutral run
dfs_moral_trait_neutral_models = [gemma_greedy_neutral[moral_traits].astype(float),gemma_top_k_neutral[moral_traits].astype(float),gemma_top_p_neutral[moral_traits].astype(float) ]

#greedy comparison
labels = ['Greedy (No Neutral)', 'Greedy']
comparison_emotion_occurrences(dfs_moral_trait_gemma_greedy, labels, "Moral Traits Distribution Comparison Greedy")


#top k comparison
labels = ['Top K (No Neutral)', 'Top K']
comparison_emotion_occurrences(dfs_moral_trait_gemma_top_k, labels, "Moral Traits Distribution Comparison Top K = 50")

#top p comparison
labels = ['Top P (No Neutral)', 'Top P']
comparison_emotion_occurrences(dfs_moral_trait_gemma_top_p, labels, "Moral Traits Distribution Comparison Top P")

#comparison all non neutral model
labels = ['Greedy', 'Top K', 'Top P']
comparison_emotion_occurrences(dfs_moral_trait_all_models, labels, "Moral Traits Distribution Comparison All Models")

#comparison all neutral model
labels = ['Greedy Neutral', 'Top K Neutral', 'Top P Neutral']
comparison_emotion_occurrences(dfs_moral_trait_neutral_models, labels, "Moral Traits Distribution Comparison All Neutral Models")

# Comparing two distributions at a time for neutral and non-neutral run
dfs_emotion_gemma_greedy = [gemma_greedy[emotions].astype(float), gemma_greedy_neutral[emotions].astype(float)]
dfs_emotion_gemma_top_k = [gemma_top_k[emotions].astype(float), gemma_top_k_neutral[emotions].astype(float)]
dfs_emotion_gemma_top_p = [gemma_top_p[emotions].astype(float), gemma_top_p_neutral[emotions].astype(float)]

# Comparing all non-neutral runs
dfs_emotion_all_models = [gemma_greedy[emotions].astype(float), gemma_top_k[emotions].astype(float), gemma_top_p[emotions].astype(float)]

# Comparing all neutral runs
dfs_emotion_neutral_models = [gemma_greedy_neutral[emotions].astype(float), gemma_top_k_neutral[emotions].astype(float), gemma_top_p_neutral[emotions].astype(float)]

# Greedy comparison
labels = ['Greedy (No Neutral)', 'Greedy']
comparison_emotion_occurrences(dfs_emotion_gemma_greedy, labels, "Emotions Distribution Comparison Greedy")

# Top K comparison
labels = ['Top K (No Neutral)', 'Top K']
comparison_emotion_occurrences(dfs_emotion_gemma_top_k, labels, "Emotions Distribution Comparison Top K = 50")

# Top P comparison
labels = ['Top P (No Neutral)', 'Top P']
comparison_emotion_occurrences(dfs_emotion_gemma_top_p, labels, "Emotions Distribution Comparison Top P")

# Comparison all non-neutral models
labels = ['Greedy', 'Top K', 'Top P']
comparison_emotion_occurrences(dfs_emotion_all_models, labels, "Emotions Distribution Comparison All Models")

# Comparison all neutral models
labels = ['Greedy Neutral', 'Top K Neutral', 'Top P Neutral']
comparison_emotion_occurrences(dfs_emotion_neutral_models, labels, "Emotions Distribution Comparison All Neutral Models")

"""Nel caso in cui viene preclusa la possibilità di annotare la neutralità delle emozioni risulta prevalere nelle annotazioni l'ottimismo con un totale di 160 annotazioni circa. Le altre emozioni maggiormente rilevate sono: antipation, trust, joy, surprise, love e pessimism con una range di annotazioni che va dalle 120 alle 140. L'emozione meno rilevata è *disgust*.

Confrontando la distribuzione delle emozioni tra i modelli con e senza l'elemento neutral si nota come l'andamento della distribuzione delle varie configurazioni sia abbastanza simile e coerente. Diverse emozioni risultano essere presenti con la stessa frequenza, per esempio le emozioni anticipation, trust, joy, surprise, love e pessimism sono statte annotate per un totale di 120 volte circa in tutte le configurazioni. Si ha poi un picco nel caso in cui si considera l'emozione no_emotion con un numero di annotazioni che supera il 160 accompagnata dall'emozione optimism. Le emozioni che risultano essere meno rilevate sono disgust e fear con un numero di annotaizoni che si aggira dalle 50 alle 60.

Questa poca differenza nel numero di annotazioni mostra come l'introduzione della neutralità non introduce un cambiamento significativo nel comportamento del modello in quanto i valori delle annotazioni sono per lo più invariati. Ciò suggerisce una maggiore difficoltà da parte di Gemma nella comprensione e annotazione della neutralità dei testi.

### **4.1.2 Analisi della Correlazione**
"""

corr_greedy_emotion = correlation_matrix(gemma_greedy[emotions].astype(float), 'Correlation Matrix for gemma GREEDY Emotions')

corr_greedy_neutral_emotion = correlation_matrix_neutral(gemma_greedy_neutral[emotions].astype(float), 'Correlation Matrix for gemma GREEDY NEUTRAL Emotions')

corr_top_k_emotion = correlation_matrix(gemma_top_k[emotions].astype(float), 'Correlation Matrix for gemma TOP K Emotions')

corr_top_k_neutral_emotion = correlation_matrix_neutral(gemma_top_k_neutral[emotions].astype(float), 'Correlation Matrix for gemma TOP K NEUTRAL Emotions')

corr_top_p_emotion = correlation_matrix(gemma_top_p[emotions].astype(float), 'Correlation Matrix for gemma TOP P Emotions')

corr_top_p_neutral_emotion = correlation_matrix_neutral(gemma_top_p_neutral[emotions].astype(float), 'Correlation Matrix for gemma TOP P NEUTRAL Emotions')

"""Emozioni come **gioia**, **fiducia** e **ottimismo** sono spesso fortemente correlate tra loro, mentre **tristezza**, **rabbia**, **pessimismo** e **paura** si raggruppano in un altro insieme, tipicamente associato a stati emotivi negativi.

Un aspetto rilevante è che le correlazioni tra emozioni positive e negative risultano generalmente basse o negative, indicando una chiara distinzione tra i due gruppi.

Tuttavia, alcune emozioni, come la **sorpresa**, rappresentano un'eccezione, se pur con correlazione bassa, potendo agire come un ponte tra stati positivi e negativi a seconda del contesto in cui si manifestano. Questa ambivalenza sottolinea che, sebbene la separazione tra emozioni positive e negative sia predominante, non tutte le emozioni si conformano rigidamente a questa divisione binaria.

**Moral Traits Correlations**
"""

corr_greedy_moral = correlation_matrix(gemma_greedy[moral_traits].astype(float), 'Correlation Matrix for gemma GREEDY Moral Traits')

corr_greedy_neutral_moral = correlation_matrix_neutral(gemma_greedy_neutral[moral_traits].astype(float), 'Correlation Matrix for gemma GREEDY NEUTRAL Moral traits')

corr_top_k_moral = correlation_matrix(gemma_top_k[moral_traits].astype(float), 'Correlation Matrix for gemma TOP K Moral Traits')

corr_top_k_neutral_moral = correlation_matrix_neutral(gemma_top_k_neutral[moral_traits].astype(float), 'Correlation Matrix for gemma TOP K NEUTRAL Moral Traits')

corr_top_p_moral = correlation_matrix(gemma_top_p[moral_traits].astype(float), 'Correlation Matrix for gemma TOP P Moral traits')

corr_top_p_neutral_moral = correlation_matrix_neutral(gemma_top_p_neutral[moral_traits].astype(float), 'Correlation Matrix for gemma TOP P NEUTRAL Moral traits')

"""
Un aspetto interessante è la presenza di relazioni contrastanti tra alcuni tratti. Ad esempio, **fairness** e **degradation** appaiono come con una correlazione pari 0.36, indicando che il modello li percepisce come leggermente coesistenti.  

La seconda matrice introduce un nuovo attributo, **"no moral"**, che rappresenta l'assenza o la neutralità rispetto a un giudizio morale. L'aggiunta di questo attributo modifica leggermente l'intensità di alcune correlazioni tra i tratti "puri", ma la struttura generale della matrice rimane sostanzialmente invariata, confermando la netta separazione tra tratti positivi e negativi.  

"""

#Confronto modelli senza neutrale
correlations = [corr_greedy_emotion, corr_top_k_emotion, corr_top_p_emotion]
correlation_comparison(correlations, emotions)
#Confronto modelli con neutrale
correlations = [corr_greedy_neutral_emotion, corr_top_k_neutral_emotion, corr_top_p_neutral_emotion]
correlation_comparison(correlations, emotions)

#Confronto modelli senza neutrale
correlations = [corr_greedy_moral, corr_top_k_moral, corr_top_p_moral]
correlation_comparison(correlations, moral_traits)
#Confronto modelli con neutrale
correlations = [corr_greedy_neutral_moral, corr_top_k_neutral_moral, corr_top_p_neutral_moral]
correlation_comparison(correlations, moral_traits)

"""E' evidente che le differenze assolute tra le correlazioni riportate per le configurazioni Greedy, Top K e Top P sono spesso vicine allo zero, il picco massimo viene raggiunto dalla relazione tra purity_score e betrayal_score con un valore pari a 0.10 (per i tratti morali) e dalle emozioni fear e pessimism con un valore pari a 0.6. Questo suggerisce che, sebbene ci siano variazioni nei risultati, i tre metodi producono annotazioni che non si discostano significativamente l'una dall'altra.

Ciò implica che l'influenza del metodo di configurazione (Greedy, Top K o Top P) è relativamente contenuta nel determinare le differenze nei pattern di annotazione per questi tratti morali. Tuttavia, le piccole differenze potrebbero comunque rivelare informazioni interessanti su sfumature nelle performance di ciascun metodo.

### **4.1.3 Qual è il rapporto tra le emozioni neutrali e le emozioni esplicite?**
"""

names = ['Greedy', 'Top K', 'Top P']
analyze_neutral_correlation(dfs_moral_trait_neutral_models, 'no moral', names, "Moral Traits")
analyze_neutral_correlation(dfs_emotion_neutral_models, 'no emotion', names)

"""Le correlazioni positive indicano situazioni in cui "Neutral" tende a manifestarsi insieme ad altre emozioni, mentre quelle negative segnalano un'antitesi.

Per tutti i tratti morali, le correlazioni con "Neutral" sono negative, indicando che un aumento di neutralità è associato a una riduzione della presenza di quei tratti morali.
La configurazione Top P mostra generalmente una correlazione meno negativa rispetto a Greedy e Top K.
Vi è una forte correlazione negativa del tratto "Neutral" scon tratti come "care", "harm", "fairness" che presentano un valore di correlazione negativa in modulo superiore a 0.5.

Per quanto riguarda le emozioni la presenza di correlazioni negative conferma che alcune emozioni sono intrinsecamente incompatibili con la neutralità, mentre altre possono coesistere in modo più fluido, per esempio le emozioni: *joy, optimism e love*.
Tali emozioni potrebbero mostrare correlazioni debolmente positive in alcune configurazioni, riflettendo contesti in cui uno stato neutrale non preclude la comparsa di sentimenti positivi. Al contrario, emozioni intense come **disgusto** potrebbero correlarsi negativamente (con un valore pari a 0.2) con "Neutral", poiché implicano un coinvolgimento emotivo marcato, incompatibile con la neutralità.  

In sintesi, il grafico sottolinea come la scelta della strategia di decodifica influenzi profondamente l'interpretazione delle emozioni. Configurazioni esplorative come il *Top-p* sembrano avvicinarsi a una rappresentazione più realistica della complessità umana, dove neutralità ed emozioni specifiche non si escludono sempre. Al contrario, approcci conservativi come il *Greedy* potrebbero semplificare eccessivamente la realtà, perdendo sfumature cruciali.


"""

compare_scores_horizontal(gemma_greedy_neutral, gemma_greedy, emotions)
compare_scores_horizontal(gemma_greedy_neutral, gemma_greedy, moral_traits)

compare_scores_horizontal(gemma_top_k_neutral, gemma_top_k, emotions)
compare_scores_horizontal(gemma_top_k_neutral, gemma_top_k, moral_traits)

compare_scores_horizontal(gemma_top_p_neutral, gemma_top_p, emotions)
compare_scores_horizontal(gemma_top_p_neutral, gemma_top_p, moral_traits)

"""Nel caso del modello Gemma, la configurazione greedy mostra un comportamento simile a quello degli altri modelli, con gli score che tendono a rimanere invariati. Tuttavia, Gemma si distingue per un comportamento migliore rispetto a Llama e Mistral, con molti score che diminuiscono correttamente in presenza di neutralità.

Con la configurazione top-k, Gemma si comporta in modo diverso a seconda del contesto: per le emozioni, il modello gestisce bene la neutralità, diminuendo gli score come previsto, mentre per i tratti morali si osservano più anomalie, con un aumento inatteso degli score.

La configurazione top-p, invece, mostra un comportamento simile al greedy, con la maggior parte degli score che rimane invariata quando si introduce la neutralità, suggerendo che Gemma potrebbe avere difficoltà a gestire la neutralità con questo metodo di decoding.

### **4.1.4 Distibuzioni**
"""

emotion_distribution_across_texts(gemma_greedy_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait greedy decoding")
emotion_distribution(gemma_greedy_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait greedy decoding")

emotion_distribution_across_texts(gemma_greedy[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait greedy decoding without Neutral")
emotion_distribution(gemma_greedy[columns[6:28]], "Distribution for Each Emotion and Moral Trait greedy decoding without Neutral")

emotion_distribution_across_texts(gemma_top_k_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-k decoding")
emotion_distribution(gemma_top_k_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait top K decoding")

emotion_distribution_across_texts(gemma_top_k[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-k decoding without Neutral")
emotion_distribution(gemma_top_k[columns[6:28]], "Distribution for Each Emotion and Moral Trait top K decoding without Neutral")

emotion_distribution_across_texts(gemma_top_p_neutral[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-p decoding")
emotion_distribution(gemma_top_p_neutral[columns[6:28]], "Distribution for Each Emotion and Moral Trait top P decoding")

emotion_distribution_across_texts(gemma_top_p[columns[6:28]], "Distribution in texts for Each Emotion and Moral Trait Top-p decoding")
emotion_distribution(gemma_top_p[columns[6:28]], "Distribution for Each Emotion and Moral Trait top P decoding without Neutral")

"""Analizzando i due tipi di distribuzioni, emergono alcune osservazioni significative:
1. **Distribuzione delle emozioni e tratti morali nei testi**:  
   Dall'analisi dei grafici, si evince che, indipendentemente dalla tecnica di decoding utilizzata, la presenza di emozioni o tratti morali è più frequente rispetto alla loro assenza.

2. **Distribuzione degli score delle emozioni e tratti morali**:  
   La tecnica di **greedy decoding** assegna punteggi principlamente o molto bassi o molto alti. I valori di score più frequenti per le emozioni (o i tratti morali) analizzati variano in un range che va da 0 a 0.3. Comportamento analogo ha la strategia di decoding *top-p* Al contrario, la modalità **Top-k** produce una gamma di punteggi più diversificata, mostrando picchi di frequenza in range di punteggi come [0.2 - 0.4] e anche [0.6 - 0.8]. Questa variabilità suggerisce che queste tecniche esplorative siano più sensibili alle sfumature del testo.

### **4.1.5 Entropia**
"""

names = ['Greedy', 'Greedy Neutral', 'Top K', 'Top K Neutral', 'Top P', 'Top P Neutral']
dfs = [gemma_greedy, gemma_greedy_neutral, gemma_top_k, gemma_top_k_neutral, gemma_top_p, gemma_top_p_neutral]
entropies = create_entropy_table(dfs, names, emotions, moral_traits)
entropies

"""I risultati dell'analisi sull'entropia rivelano che l'introduzione della modalità **"Neutral"** incrementa la diversità nelle annotazioni, sia per le emozioni che per i tratti morali. Questo aumento, osservato in tutte le configurazioni (Greedy, Top K, Top P), suggerisce che la classe "Neutral" agisca come catalizzatore di ambiguità, distribuendo le probabilità in modo più uniforme e assorbendo casi non chiaramente polarizzati.

L'effetto della modalità "Neutral" è più marcato nei tratti morali, con un aumento dell'entropia più significativo rispetto alle emozioni. Ad esempio, nella configurazione **Greedy**, l'entropia passa da **2.882** a **3.042** per i tratti morali, mentre nelle emozioni cresce da **3.267** a **3.390**. Questo suggerisce che la neutralità introduce una maggiore diversità interpretativa nei tratti morali, confermando la loro natura più complessa e soggetta a interpretazioni più sfumate.

Le tecniche esplorative (**Top K** e **Top P**), specialmente quando combinate con "Neutral", mostrano valori di entropia leggermente superiori, riflettendo una maggiore capacità di gestire sfumature complesse rispetto al metodo **Greedy**, più conservativo.  

Un altro aspetto chiave è la differenza tra emozioni e tratti morali: le prime presentano entropie costantemente più elevate, mentre i secondi sono caratterizzati da una distribuzione più coerente, probabilmente per la loro connessione a principi etici meglio definiti.

### **4.1.6 Comparison Positive and Negative Emotions/Moral Traits**
"""

compare_positive_negative_emotions(gemma_greedy, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions GREEDY")
compare_positive_negative_emotions(gemma_greedy_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions GREEDY NEUTRAL")
compare_positive_negative_emotions(gemma_top_k, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP K")
compare_positive_negative_emotions(gemma_top_k_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP K NEUTRAL")
compare_positive_negative_emotions(gemma_top_p, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP P")
compare_positive_negative_emotions(gemma_top_p_neutral, positive_emotions, negative_emotions, "Comparison Between Positive and Negative Emotions TOP P NEUTRAL")

"""Vi è uno sbilanciamento nelle annotazioni, in quanto vengono rilevate molte più emozioni positive o tratti morali positivi.

Una possibile spiegazione di questo sbilanciamento potrebbe risiedere nella natura dei testi analizzate. Se il dataset è composto principalmente da articoli con una prospettiva etica, orientata alla giustizia sociale, alla cura o alla protezione degli individui, è naturale che i modelli rilevino più frequentemente tratti morali positivi. Al contrario, se il corpus di testo avesse incluso più contenuti legati a dinamiche di potere, conservatorismo o conflitti sociali, i punteggi relativi a "authority_scores" o "loyalty_scores" potrebbero essere stati più alti.

Questo fenomeno può derivare anche dai criteri con cui sono state annotate le news. Se gli annotatori hanno inconsapevolmente enfatizzato il valore morale positivo delle narrazioni, oppure se il modello stesso ha una tendenza a rilevare tratti morali più accettabili socialmente, lo sbilanciamento potrebbe essere amplificato.

## **4.2 Conclusioni per Gemma**

Il modello Gemma 2 ha mostrato un'alta sensibilità nel rilevamento delle emozioni specifiche, in particolare quelle positive come Optimism e Joy, che si sono distinte per frequenze elevate in tutte le configurazioni. Tuttavia, l'aggiunta della classe "Neutral" ha portato a un significativo aumento di annotazioni neutre, spesso a scapito delle altre emozioni. Questo comportamento sottolinea un limite del modello nel bilanciare accuratezza e diversità quando si tratta di testi complessi e con annotazioni multilivello.

# **5. Confronto Risultati dei modelli**

LLAMA 3.1 ha dimostrato una netta superiorità del **top-p sampling** nella rilevazione di emozioni e tratti morali, mentre il *greedy decoding* si è rivelato rigido e polarizzante.

Mistral, al contrario, ha mostrato comportamenti contrastanti: ottimale con **greedy decoding** per i tratti morali e con **top-p sampling** per le emozioni, mantenendo comunque una distribuzione equilibrata dei risultati.

Gemma 2, invece, non ha evidenziato una tecnica dominante, se non un lieve vantaggio del **top-k sampling** in contesti specifici, confermando una tendenza alla polarizzazione simile a LLAMA con il *greedy decoding*.  

L'esclusione della classe neutrale ha accentuato la **polarizzazione** in LLAMA e Gemma, spingendo i modelli verso annotazioni estreme, mentre Mistral ha mantenuto una maggiore **moderazione**. Questo suggerisce che la mancanza di opzioni neutrali possa amplificare bias intrinseci, ovvero, una tendenza sistematica e prevedibile dei un modelli a produrre output polarizzati o sbilanciati, derivante dalla loro natura algoritmica rigidamente strutturata e dall'assenza di meccanismi che introducano variabilità nel processo decisionale.

LLAMA ha registrato la correlazione più alta per le emozioni, mentre Mistral si è distinto nei tratti morali, riflettendo la sua capacità di bilanciamento. Le distribuzioni hanno confermato **picchi estremi** in LLAMA e Gemma con *greedy decoding*, contro curve più piatte in Mistral, indicando una **gestione più sfumata delle ambiguità**.

Tutti i modelli hanno **privilegiato emozioni e tratti positivi**, probabilmente a causa di bias nel dataset (es. articoli ottimistici) o nell'addestramento dei modelli, con un effetto rinforzato dalle tecniche di decoding esplorative.  

Mistral ha mostrato un'**entropia più elevata**, segno di maggiore diversità nelle annotazioni, mentre LLAMA e Gemma hanno migliorato la variabilità solo con *top-p/top-k sampling*, evidenziando limiti nel *greedy decoding*.

La scelta del modello e del decoding dipende dal contesto: Mistral è ideale per **tasks bilanciate**, LLAMA e Gemma per **classificazioni nette**. Tuttavia, i risultati sono influenzati da bias campionari, richiedendo validazione su dataset più ampi e rappresentativi.

# **6. Confronto tra modelli (K-statistics)**

La k-statistica (o kappa di Cohen) è una misura comunemente utilizzata per valutare l'accordo tra annotatori o modelli nel contesto dell'annotazione dei dati. Nel caso specifico dell'analisi di testi per la presenza di emozioni e tratti morali tramite un modello di NLP come LLaMA 3.1, la k-statistica rappresenta uno strumento fondamentale per quantificare la coerenza e l'affidabilità delle annotazioni. Questa metrica va oltre il semplice calcolo della percentuale di accordo, poiché tiene conto della probabilità di accordo casuale, rendendola particolarmente utile in contesti dove alcune categorie (come emozioni o tratti morali positivi) potrebbero essere più frequenti di altre.

Il valore di kappa varia tra -1 e 1, dove: 1 indica un accordo perfetto, 0 indica che l'accordo osservato è pari a quello atteso casualmente e invece valori negativi suggeriscono un accordo inferiore a quello casuale, evidenziando discrepanze significative.

Valori tipici di interpretazione: < 0.20: Accordò scarso 0.21 - 0.40: Accordo discreto 0.41 - 0.60: Accordo moderato 0.61 - 0.80: Accordo sostanziale 0.81 - 1.00: Accordo quasi perfetto
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import cohen_kappa_score
from statsmodels.stats.inter_rater import fleiss_kappa


def discretize_values(df, emotion, bins=11):
    return pd.cut(df[emotion], bins=bins, labels=False)

def calculate_kappa_for_emotions(dfs, emotions, bins = 11):
    # Dictionary to store the Kappa results for each emotion
    kappa_results = {}

    if len(dfs) == 2:
        # Use Cohen's Kappa for two runs
        for emotion in emotions:
            # Discretize the continuous values
            discretized_1 = discretize_values(dfs[0], emotion, bins = bins)
            discretized_2 = discretize_values(dfs[1], emotion, bins = bins)
            kappa_score = cohen_kappa_score(discretized_1, discretized_2)
            kappa_results[emotion] = kappa_score
    else:
        # Use Fleiss Kappa for more than two runs
        for emotion in emotions:
            # Prepare data for Fleiss Kappa: create a matrix with annotations for each run/emotion
            ratings = pd.DataFrame({f"run_{i+1}": dfs[i][emotion] for i in range(len(dfs))}).T
            # Convert each score to frequencies (counts of each value from 0 to 1)
            counts = ratings.apply(lambda x: x.value_counts(normalize=False), axis=0).fillna(0).astype(int).T
            kappa_score = fleiss_kappa(counts)
            kappa_results[emotion] = kappa_score

    return kappa_results

def plot_kappa_scores(kappa_scores, title):
    # Convert results to a DataFrame for easy visualization
    kappa_df = pd.DataFrame(list(kappa_scores.items()), columns=['Emotion', 'Kappa Score'])
    kappa_df.sort_values(by='Kappa Score', ascending=False, inplace=True)

    # Add categories based on Kappa Score
    def categorize(score):
        if score < 0.2:
            return "Scarsa"
        elif score < 0.4:
            return "Discreta"
        elif score < 0.6:
            return "Moderata"
        elif score < 0.8:
            return "Buona"
        else:
            return "Eccellente"

    kappa_df['Category'] = kappa_df['Kappa Score'].apply(categorize)

    # Create a colormap and normalization
    cmap = plt.cm.coolwarm
    norm = plt.Normalize(vmin=kappa_df['Kappa Score'].min(), vmax=kappa_df['Kappa Score'].max())

    # Create the figure and axis
    fig, ax = plt.subplots(figsize=(12, 8))

    # Create the horizontal bar chart
    bars = ax.barh(kappa_df['Emotion'], kappa_df['Kappa Score'], color=cmap(norm(kappa_df['Kappa Score'])))

    # Add values and categories to the bars
    for bar, (score, category) in zip(bars, zip(kappa_df['Kappa Score'], kappa_df['Category'])):
        ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2, f'{score:.2f} ({category})', va='center', fontsize=10, color='black')


    ax.set_xlim(-0.23, 1)

    # Add a colorbar to represent the Kappa Score
    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])  # Required for ScalarMappable to work
    cbar = fig.colorbar(sm, ax=ax)
    cbar.set_label('Kappa Score', rotation=270, labelpad=15)

    # Add a threshold line for good agreement (e.g., 0.6)
    ax.axvline(x=0.6, color='red', linestyle='--', label='Soglia: Buona concordanza')

    # Add labels, title, and legend
    ax.set_xlabel('Kappa Score')
    ax.set_ylabel('Emotion')
    ax.set_title(title)
    ax.invert_yaxis()  # Invert the y-axis to show the highest scores at the top
    ax.legend(loc='lower right')

    # Add an interpretation text below the graph
    fig.text(0.5, -0.05, "Interpretazione Kappa: <0.2=Scarsa, 0.2–0.4=Discreta, 0.4–0.6=Moderata, 0.6–0.8=Buona, >0.8=Eccellente",
             wrap=True, horizontalalignment='center', fontsize=10)

    # Show the plot
    plt.show()

"""## **6.1. Calcolo K-statistica fra LLAMA e Mistral**




"""

#EMOZIONI

dfs_greedy = [llama_greedy, mistral_greedy]
dfs_greedy_neutral = [llama_greedy_neutral, mistral_greedy_neutral]


dfs_top_k = [llama_top_k, mistral_top_k]
dfs_top_k_neutral = [llama_top_k_neutral, mistral_top_k_neutral]


dfs_top_p = [llama_top_p, mistral_top_p]
dfs_top_p_neutral = [llama_top_p_neutral, mistral_top_p_neutral]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, emotions)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, emotions)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, emotions)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, emotions)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, emotions)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, emotions)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

#TRATTI MORALI
dfs_greedy = [llama_greedy, mistral_greedy]
dfs_greedy_neutral = [llama_greedy_neutral, mistral_greedy_neutral]


dfs_top_k = [llama_top_k, mistral_top_k]
dfs_top_k_neutral = [llama_top_k_neutral, mistral_top_k_neutral]


dfs_top_p = [llama_top_p, mistral_top_p]
dfs_top_p_neutral = [llama_top_p_neutral, mistral_top_p_neutral]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, moral_traits)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, moral_traits)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, moral_traits)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, moral_traits)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, moral_traits)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, moral_traits)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

"""## **6.2. Calcolo K-statistica fra LLAMA e Gemma**"""

#EMOZIONI
dfs_greedy = [llama_greedy, gemma_greedy]
dfs_greedy_neutral = [llama_greedy_neutral, gemma_greedy_neutral]


dfs_top_k = [llama_top_k, gemma_top_k]
dfs_top_k_neutral = [llama_top_k_neutral, gemma_top_k_neutral]


dfs_top_p = [llama_top_p, gemma_top_p]
dfs_top_p_neutral = [llama_top_p_neutral, gemma_top_p_neutral]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, emotions)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, emotions)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, emotions)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, emotions)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, emotions)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, emotions)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

#TRATTI MORALI
dfs_greedy = [llama_greedy, gemma_greedy]
dfs_greedy_neutral = [llama_greedy_neutral, gemma_greedy_neutral]


dfs_top_k = [llama_top_k, gemma_top_k]
dfs_top_k_neutral = [llama_top_k_neutral, gemma_top_k_neutral]


dfs_top_p = [llama_top_p, gemma_top_p]
dfs_top_p_neutral = [llama_top_p_neutral, gemma_top_p_neutral]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, moral_traits)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, moral_traits)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, moral_traits)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, moral_traits)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, moral_traits)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, moral_traits)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

"""## **6.3 Calcolo K-statistica fra Mistral e Gemma**

"""

#EMOZIONI

dfs_greedy = [mistral_greedy, gemma_greedy]
dfs_greedy_neutral = [mistral_greedy_neutral, gemma_greedy_neutral]


dfs_top_k = [mistral_top_k, gemma_top_k]
dfs_top_k_neutral = [mistral_top_k_neutral, gemma_top_k_neutral]


dfs_top_p = [mistral_top_p, gemma_top_p]
dfs_top_p_neutral = [mistral_top_p_neutral, gemma_top_p_neutral]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, emotions)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, emotions)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, emotions)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, emotions)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, emotions)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, emotions)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

#TRATTI MORALI

dfs_greedy = [mistral_greedy, gemma_greedy]
dfs_greedy_neutral = [mistral_greedy_neutral, gemma_greedy_neutral]


dfs_top_k = [mistral_top_k, gemma_top_k]
dfs_top_k_neutral = [mistral_top_k_neutral, gemma_top_k_neutral]


dfs_top_p = [mistral_top_p, gemma_top_p]
dfs_top_p_neutral = [mistral_top_p_neutral, gemma_top_p_neutral]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, moral_traits)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, moral_traits)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, moral_traits)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, moral_traits)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, moral_traits)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, moral_traits)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

"""## **6.4 Confronto fra tutti i modelli**"""

#EMOZIONI

dfs_greedy = [llama_greedy, mistral_greedy, gemma_greedy]
dfs_greedy_neutral = [llama_greedy_neutral, mistral_greedy_neutral, gemma_greedy_neutral]


dfs_top_k = [llama_top_k, mistral_top_k, gemma_top_k]
dfs_top_k_neutral = [llama_top_k_neutral, mistral_top_k_neutral, gemma_top_k_neutral]


dfs_top_p = [llama_top_p, mistral_top_p, gemma_top_p]
dfs_top_p_neutral = [llama_top_p_neutral, mistral_top_p_neutral, gemma_top_p_neutral]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, emotions)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, emotions)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, emotions)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, emotions)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, emotions)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, emotions)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

#TRATTI MORALI

dfs_greedy = [llama_greedy, mistral_greedy, gemma_greedy]
dfs_greedy_neutral = [llama_greedy_neutral, mistral_greedy_neutral, gemma_greedy_neutral]


dfs_top_k = [llama_top_k, mistral_top_k, gemma_top_k]
dfs_top_k_neutral = [llama_top_k_neutral, mistral_top_k_neutral, gemma_top_k_neutral]


dfs_top_p = [llama_top_p, mistral_top_p, gemma_top_p]
dfs_top_p_neutral = [llama_top_p_neutral, mistral_top_p_neutral, gemma_top_p_neutral]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, moral_traits)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, moral_traits)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, moral_traits)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, moral_traits)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, moral_traits)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, moral_traits)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

"""Per l'analisi della k-statistica sono stati effettuati diversi confronti. Prima tra coppie di modelli e poi, tramite la *Fleiss* statistica, il confronto con tutti e tre i modelli. Le analisi effettuate fanno concludere che, per ogni coppia di modelli, l'accordo sull'assegnamento degli score alle emozioni (o tratti morali) risulta essere molto scarso. Raramente, e solo per alcune emozioni (o tratti morali), vengono raggiunti score come 0.32.

Nella letteratura statistica, un k ≥ 0.6 è considerato indicativo di accordo moderato, mentre valori inferiori a 0.4 segnalano discrepanze sostanziali. Pertanto, il picco di 0.32 riflette al massimo una **convergenza marginale**, insufficiente per validare l'affidabilità di questi modelli in un contesto di annotazione automatica.  

Il poco accordo tra coppie si è poi manifestato anche nel confronto finale considerando tutti e tre i modelli. I valori per ogni emozione infatti sono compresi tra -0.07 e 0.17, mentre per i tratti morali il range di valori va da -0.12 a un massimo di 0.12, indicando che non vi è alcuna relazione tra le diverse assegnazioni degli score dei diversi metodi.

Questi intervalli, comprendenti valori negativi, indicano che in alcuni casi **l'accordo è peggiore di quanto atteso casualmente**, segnalando un **disaccordo** nelle logiche di classificazione. Ad esempio, un k negativo (-0.12) per certi tratti morali implica che i modelli non solo non concordano, ma **tendono a polarizzarsi in direzioni opposte**, amplificando incoerenze intrinseche.  

La bassa concordanza solleva dubbi sulla **riproducibilità** degli score, soprattutto in contesti applicativi (es., analisi di sentimenti o etica computazionale). Un k < 0.2 per la maggior parte delle categorie suggerisce che i punteggi siano **influenzati più da rumore algoritmico che da pattern coerenti**.

# **7 Confronto della *detection* tra modelli (K-statistics)**

Dati gli scarsi risultati ottenuti dall'analisi della K-statistica sull'assegnazione degli score dei diversi modelli, si è pensato di analizzare la detection delle emozioni. Per fare ciò si sono binarizzati i dataframe contenenti i risultati seguendo la seguente logica:

\begin{equation}
 \text{binarized value} = \begin{cases}
 1 & \text{if score} > 0.2\\
 0 & \text{otherwise}
 \end{cases}
\end{equation}
"""

# Define columns to binarize
moral_traits = ['care_scores', 'harm_scores', 'fairness_scores', 'cheating_scores',
                'loyalty_scores', 'betrayal_scores', 'authority_scores', 'subversion_scores',
                'purity_scores', 'degradation_scores', 'no moral']

emotions = ['anticipation', 'trust', 'disgust',
            'joy', 'optimism', 'surprise', 'love', 'anger', 'sadness', 'pessimism',
            'fear', 'no emotion']

# Function to selectively binarize columns
def binarize_selected_columns(df, columns):
    # Find intersection of DataFrame columns and specified columns
    cols = df.columns.intersection(columns)
    # Binarize selected columns (set to 1 if value > 0, else 0)
    df.loc[:, cols] = (df[cols] > 0.2).astype(int)
    return df

# =============================================================================
# Llama - Binarization of specific columns
# =============================================================================
llama_greedy_neutral_bin = binarize_selected_columns(llama_greedy_neutral.copy(), moral_traits + emotions)
llama_greedy_bin = binarize_selected_columns(llama_greedy.copy(), moral_traits + emotions)
llama_top_k_neutral_bin = binarize_selected_columns(llama_top_k_neutral.copy(), moral_traits + emotions)
llama_top_k_bin = binarize_selected_columns(llama_top_k.copy(), moral_traits + emotions)
llama_top_p_neutral_bin = binarize_selected_columns(llama_top_p_neutral.copy(), moral_traits + emotions)
llama_top_p_bin = binarize_selected_columns(llama_top_p.copy(), moral_traits + emotions)

# =============================================================================
# Mistral - Binarization of specific columns
# =============================================================================
mistral_greedy_neutral_bin = binarize_selected_columns(mistral_greedy_neutral.copy(), moral_traits + emotions)
mistral_greedy_bin = binarize_selected_columns(mistral_greedy.copy(), moral_traits + emotions)
mistral_top_k_neutral_bin = binarize_selected_columns(mistral_top_k_neutral.copy(), moral_traits + emotions)
mistral_top_k_bin = binarize_selected_columns(mistral_top_k.copy(), moral_traits + emotions)
mistral_top_p_neutral_bin = binarize_selected_columns(mistral_top_p_neutral.copy(), moral_traits + emotions)
mistral_top_p_bin = binarize_selected_columns(mistral_top_p.copy(), moral_traits + emotions)

# =============================================================================
# Gemma - Binarization of specific columns
# =============================================================================
gemma_greedy_neutral_bin = binarize_selected_columns(gemma_greedy_neutral.copy(), moral_traits + emotions)
gemma_greedy_bin = binarize_selected_columns(gemma_greedy.copy(), moral_traits + emotions)
gemma_top_k_neutral_bin = binarize_selected_columns(gemma_top_k_neutral.copy(), moral_traits + emotions)
gemma_top_k_bin = binarize_selected_columns(gemma_top_k.copy(), moral_traits + emotions)
gemma_top_p_neutral_bin = binarize_selected_columns(gemma_top_p_neutral.copy(), moral_traits + emotions)
gemma_top_p_bin = binarize_selected_columns(gemma_top_p.copy(), moral_traits + emotions)

"""## **7.1 Calcolo K-statistica per la detection fra LLAMA e Mistral**"""

#EMOTIONS

dfs_greedy = [llama_greedy_bin, mistral_greedy_bin]
dfs_greedy_neutral = [llama_greedy_neutral_bin, mistral_greedy_neutral_bin]


dfs_top_k = [llama_top_k_bin, mistral_top_k_bin]
dfs_top_k_neutral = [llama_top_k_neutral_bin, mistral_top_k_neutral_bin]


dfs_top_p = [llama_top_p_bin, mistral_top_p_bin]
dfs_top_p_neutral = [llama_top_p_neutral_bin, mistral_top_p_neutral_bin]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, emotions, bins = 2)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, emotions, bins = 2)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, emotions, bins = 2)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, emotions, bins = 2)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, emotions, bins = 2)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, emotions, bins = 2)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

#TRATTI MORALI

dfs_greedy = [llama_greedy_bin, mistral_greedy_bin]
dfs_greedy_neutral = [llama_greedy_neutral_bin, mistral_greedy_neutral_bin]


dfs_top_k = [llama_top_k_bin, mistral_top_k_bin]
dfs_top_k_neutral = [llama_top_k_neutral_bin, mistral_top_k_neutral_bin]


dfs_top_p = [llama_top_p_bin, mistral_top_p_bin]
dfs_top_p_neutral = [llama_top_p_neutral_bin, mistral_top_p_neutral_bin]


# Calcola la kappa per ogni tratto morale
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, moral_traits, bins = 2)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, moral_traits, bins = 2)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, moral_traits, bins = 2)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, moral_traits, bins = 2)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, moral_traits, bins = 2)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, moral_traits, bins = 2)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

"""## **7.2 Calcolo K-statistica per la detection fra LLAMA e Gemma**"""

#EMOZIONI

dfs_greedy = [llama_greedy_bin, gemma_greedy_bin]
dfs_greedy_neutral = [llama_greedy_neutral_bin, gemma_greedy_neutral_bin]


dfs_top_k = [llama_top_k_bin, gemma_top_k_bin]
dfs_top_k_neutral = [llama_top_k_neutral_bin, gemma_top_k_neutral_bin]


dfs_top_p = [llama_top_p_bin, gemma_top_p_bin]
dfs_top_p_neutral = [llama_top_p_neutral_bin, gemma_top_p_neutral_bin]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, emotions, bins = 2)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, emotions, bins = 2)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, emotions, bins = 2)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, emotions, bins = 2)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, emotions, bins = 2)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, emotions, bins = 2)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

#TRATTI MORALI

dfs_greedy = [llama_greedy_bin, gemma_greedy_bin]
dfs_greedy_neutral = [llama_greedy_neutral_bin, gemma_greedy_neutral_bin]


dfs_top_k = [llama_top_k_bin, gemma_top_k_bin]
dfs_top_k_neutral = [llama_top_k_neutral_bin, gemma_top_k_neutral_bin]


dfs_top_p = [llama_top_p_bin, gemma_top_p_bin]
dfs_top_p_neutral = [llama_top_p_neutral_bin, gemma_top_p_neutral_bin]


# Calcola la kappa per ogni tratto morale
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, moral_traits, bins = 2)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, moral_traits, bins = 2)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, moral_traits, bins = 2)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, moral_traits, bins = 2)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, moral_traits, bins = 2)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, moral_traits, bins = 2)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

"""## **7.3 Calcolo K-statistica per la detection fra Mistral e Gemma**"""

#EMOZIONI

dfs_greedy = [mistral_greedy_bin, gemma_greedy_bin]
dfs_greedy_neutral = [mistral_greedy_neutral_bin, gemma_greedy_neutral_bin]


dfs_top_k = [mistral_top_k_bin, gemma_top_k_bin]
dfs_top_k_neutral = [mistral_top_k_neutral_bin, gemma_top_k_neutral_bin]


dfs_top_p = [mistral_top_p_bin, gemma_top_p_bin]
dfs_top_p_neutral = [mistral_top_p_neutral_bin, gemma_top_p_neutral_bin]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy, emotions, bins = 2)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, emotions, bins = 2)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, emotions, bins = 2)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, emotions, bins = 2)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, emotions, bins = 2)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, emotions, bins = 2)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

#TRATTI MORALI

dfs_greedy = [mistral_greedy_bin, gemma_greedy_bin]
dfs_greedy_neutral = [mistral_greedy_neutral_bin, gemma_greedy_neutral_bin]


dfs_top_k = [mistral_top_k_bin, gemma_top_k_bin]
dfs_top_k_neutral = [mistral_top_k_neutral_bin, gemma_top_k_neutral_bin]


dfs_top_p = [mistral_top_p_bin, gemma_top_p_bin]
dfs_top_p_neutral = [mistral_top_p_neutral_bin, gemma_top_p_neutral_bin]


# Calcola la kappa per ogni emozione
kappa_scores_greedy = calculate_kappa_for_emotions(dfs_greedy,moral_traits, bins = 2)
kappa_scores_top_k = calculate_kappa_for_emotions(dfs_top_k, moral_traits, bins = 2)
kappa_scores_top_p = calculate_kappa_for_emotions(dfs_top_p, moral_traits, bins = 2)

plot_kappa_scores(kappa_scores_greedy, 'K-score for Greedy Model')
plot_kappa_scores(kappa_scores_top_k, 'K-score for Top-k Model')
plot_kappa_scores(kappa_scores_top_p, 'K-score for Top-p Model')

#Neutral model
kappa_scores_greedy_neutral = calculate_kappa_for_emotions(dfs_greedy_neutral, moral_traits, bins = 2)
kappa_scores_top_k_neutral = calculate_kappa_for_emotions(dfs_top_k_neutral, moral_traits, bins = 2)
kappa_scores_top_p_neutral = calculate_kappa_for_emotions(dfs_top_p_neutral, moral_traits, bins = 2)

plot_kappa_scores(kappa_scores_greedy_neutral, 'K-score for Greedy Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_k_neutral, 'K-score for Top-k Model (Neutral Run)')
plot_kappa_scores(kappa_scores_top_p_neutral, 'K-score for Top-p Model (Neutral Run)')

"""## **7.4 Confronto tra tutti i modelli**"""

# ======================================================================
# EMOZIONI - CONFIGURAZIONI BINARIZZATE
# ======================================================================

# Dataset binari senza neutral
dfs_greedy_bin = [llama_greedy_bin, mistral_greedy_bin, gemma_greedy_bin]
dfs_top_k_bin = [llama_top_k_bin, mistral_top_k_bin, gemma_top_k_bin]
dfs_top_p_bin = [llama_top_p_bin, mistral_top_p_bin, gemma_top_p_bin]

# Dataset binari con neutral
dfs_greedy_neutral_bin = [llama_greedy_neutral_bin, mistral_greedy_neutral_bin, gemma_greedy_neutral_bin]
dfs_top_k_neutral_bin = [llama_top_k_neutral_bin, mistral_top_k_neutral_bin, gemma_top_k_neutral_bin]
dfs_top_p_neutral_bin = [llama_top_p_neutral_bin, mistral_top_p_neutral_bin, gemma_top_p_neutral_bin]

# ======================================================================
# CALCOLO KAPPA PER EMOZIONI (VERSIONE BINARIZZATA)
# ======================================================================

# Senza neutral
kappa_scores_greedy_bin = calculate_kappa_for_emotions(dfs_greedy_bin, emotions, bins = 2)
kappa_scores_top_k_bin = calculate_kappa_for_emotions(dfs_top_k_bin, emotions, bins = 2)
kappa_scores_top_p_bin = calculate_kappa_for_emotions(dfs_top_p_bin, emotions, bins = 2)

plot_kappa_scores(kappa_scores_greedy_bin, 'K-score for Greedy Model (Binarized)')
plot_kappa_scores(kappa_scores_top_k_bin, 'K-score for Top-k Model (Binarized)')
plot_kappa_scores(kappa_scores_top_p_bin, 'K-score for Top-p Model (Binarized)')

# Con neutral
kappa_scores_greedy_neutral_bin = calculate_kappa_for_emotions(dfs_greedy_neutral_bin, emotions, bins = 2)
kappa_scores_top_k_neutral_bin = calculate_kappa_for_emotions(dfs_top_k_neutral_bin, emotions, bins = 2)
kappa_scores_top_p_neutral_bin = calculate_kappa_for_emotions(dfs_top_p_neutral_bin, emotions, bins = 2)

plot_kappa_scores(kappa_scores_greedy_neutral_bin, 'K-score for Greedy Model (Neutral Run - Binarized)')
plot_kappa_scores(kappa_scores_top_k_neutral_bin, 'K-score for Top-k Model (Neutral Run - Binarized)')
plot_kappa_scores(kappa_scores_top_p_neutral_bin, 'K-score for Top-p Model (Neutral Run - Binarized)')

# ======================================================================
# EMOZIONI - CONFIGURAZIONI BINARIZZATE
# ======================================================================

# Dataset binari senza neutral
dfs_greedy_bin = [llama_greedy_bin, mistral_greedy_bin, gemma_greedy_bin]
dfs_top_k_bin = [llama_top_k_bin, mistral_top_k_bin, gemma_top_k_bin]
dfs_top_p_bin = [llama_top_p_bin, mistral_top_p_bin, gemma_top_p_bin]

# Dataset binari con neutral
dfs_greedy_neutral_bin = [llama_greedy_neutral_bin, mistral_greedy_neutral_bin, gemma_greedy_neutral_bin]
dfs_top_k_neutral_bin = [llama_top_k_neutral_bin, mistral_top_k_neutral_bin, gemma_top_k_neutral_bin]
dfs_top_p_neutral_bin = [llama_top_p_neutral_bin, mistral_top_p_neutral_bin, gemma_top_p_neutral_bin]

# ======================================================================
# CALCOLO KAPPA PER EMOZIONI (VERSIONE BINARIZZATA)
# ======================================================================

# Senza neutral
kappa_scores_greedy_bin = calculate_kappa_for_emotions(dfs_greedy_bin, moral_traits, bins = 2)
kappa_scores_top_k_bin = calculate_kappa_for_emotions(dfs_top_k_bin, moral_traits, bins = 2)
kappa_scores_top_p_bin = calculate_kappa_for_emotions(dfs_top_p_bin, moral_traits, bins = 2)

plot_kappa_scores(kappa_scores_greedy_bin, 'K-score for Greedy Model (Binarized)')
plot_kappa_scores(kappa_scores_top_k_bin, 'K-score for Top-k Model (Binarized)')
plot_kappa_scores(kappa_scores_top_p_bin, 'K-score for Top-p Model (Binarized)')

# Con neutral
kappa_scores_greedy_neutral_bin = calculate_kappa_for_emotions(dfs_greedy_neutral_bin, moral_traits, bins = 2)
kappa_scores_top_k_neutral_bin = calculate_kappa_for_emotions(dfs_top_k_neutral_bin, moral_traits, bins = 2)
kappa_scores_top_p_neutral_bin = calculate_kappa_for_emotions(dfs_top_p_neutral_bin, moral_traits, bins = 2)

plot_kappa_scores(kappa_scores_greedy_neutral_bin, 'K-score for Greedy Model (Neutral Run - Binarized)')
plot_kappa_scores(kappa_scores_top_k_neutral_bin, 'K-score for Top-k Model (Neutral Run - Binarized)')
plot_kappa_scores(kappa_scores_top_p_neutral_bin, 'K-score for Top-p Model (Neutral Run - Binarized)')

"""Anche per la *detection* delle emozioni (o tratti morali) è stata fatta un'analisi comparativa prima tra coppie e poi tra tutti e tre i modelli.

I modelli in questo caso sembrano andare più d'accordo. In particolare, LLama, Mistral e Gemma sembrano raggiungere un buon livello di concordanza sulla detection delle emozioni nei testi. Le configurazioni che risultano essere maggiormente in sintonia tra loro sono quelle che prendono in considerazione la metodologia di *decoding greedy*. Ciò potrebbe essere dovuto al maggiore determinismo intrinseco della strategia di decoding che porta i modelli a una detection delle emozioni più coerente e uniforme.

Al contrario, per quanto riguarda i tratti morali, i risultati ottenuti tramite la K-statistica suggeriscono che i modelli non sono d'accordo neanche per la *detection*. In alcune configurazioni (in particolare i quelle con metodologia di decoding *greedy*) i modelli tendono ad avere **"opinioni" divergenti**. Ciò ad indicare una maggiore diversità da parte dei modelli nella rappresentazione e comprensione dei tratti morali in quanto, sono per loro natura, più complessi. Ciò sottolinea anche la diversa natura intrinseca dei LLM presi in analisi.

# **Conclusioni**

Nei media, le emozioni e i valori morali rivestono un ruolo determinante nel plasmare l'opinione pubblica e influenzare il coinvolgimento del pubblico. Questo studio si è posto l'obiettivo di esplorare e analizzare le capacità di modelli linguistici avanzati come LLama 3.1, Mistral e Gemma nel rilevamento e nell'annotazione di emozioni e tratti morali presenti in contenuti pubblicati dall'HuffPost. Attraverso l'utilizzo di due prompt distinti, uno dedicato alla valutazione delle emozioni e l'altro focalizzato sull'annotazione delle dimensioni morali, è stato possibile confrontare le performance dei modelli in tre modalità di decoding (greedy decoding, top-k sampling e top-p sampling). Inoltre, sono stati analizzati due scenari: uno che consentiva ai modelli di considerare una classe neutrale per emozioni e tratti morali, e uno in cui tale opzione era esclusa.

L'analisi condotta ha evidenziato come la scelta della configurazione di decoding e la possibilità di annotare una classe neutrale abbiano un impatto significativo sulla capacità dei modelli di fornire risultati ricchi e dettagliati. I metodi più esplorativi, come il top-k e il top-p sampling, si sono dimostrati più efficaci nel catturare una gamma diversificata di emozioni e tratti morali, sebbene l'introduzione della classe neutrale abbia mostrato un'influenza marcata, con un incremento delle annotazioni neutre spesso a scapito delle altre categorie. La combinazione di questi approcci ha permesso di individuare non solo i punti di forza e le aree di miglioramento dei modelli, ma anche le dinamiche complesse che governano l'annotazione automatica di testi con contenuti emotivi e morali.

Gli studi condotti hanno evidenziato le diverse "personalità" dei modelli presi in considerazione nell'annotazione di emozioni e tratti morali. Nonostante le loro potenzialità, tutti i modelli analizzati, inclusi LLama 3.1, Mistral e Gemma, mostrano difficoltà nella gestione della neutralità di emozioni e tratti morali. Questo limite si traduce in una frequente sovrastima della classe neutrale, che spesso penalizza la granularità e la varietà delle annotazioni.

Le analisi grafiche delle matrici di correlazione tra le emozioni e i tratti morali hanno rivelato che le annotazioni prodotte dai singoli modelli risultano generalmente coerenti, mostrando una buona correlazione interna tra le categorie rilevate. Tuttavia, la valutazione tramite K-statistiche ha messo in luce differenze significative tra i modelli: pur trovando un discreto accordo nella *detection* delle emozioni, questi stessi modelli mostrano una scarsa concordanza nella rilevazione dei tratti morali. Tale divergenza è attribuibile alla maggiore complessità intrinseca dei tratti morali, che richiedono una comprensione più profonda e contestuale rispetto alle emozioni.

Alla luce di questi risultati, l'impiego di modelli di linguaggio avanzati per l'annotazione delle emozioni appare promettente, soprattutto nelle applicazioni che richiedono un'analisi preliminare. Tuttavia, per compiti che necessitano di una maggiore precisione e accuratezza, specialmente nell'annotazione dei tratti morali, è evidente che questi strumenti necessitano di ulteriori miglioramenti. Sebbene siano utili per automatizzare processi complessi, è consigliabile integrarli con interventi umani o approcci ibridi per garantire risultati affidabili e di alta qualità, in particolare nei casi in cui la neutralità e la complessità morale giocano un ruolo cruciale.

# **A.  Prompt that works better for Each Model**

### **LLama**
Per il  modello Llama 3.1 non sono stati trovati particolari metodologie di *prompting* che servissero per aumentare la precisione delle risposte. Sulla documentazione ufficiale viene data una linea guida **[7]** che può essere riassunta nei seguenti punti:

- Essere brevi
- Essere chiari
- Raffinare il *prompt*
- Variare il *prompt*
- Usare i *feedback*.

Di seguito sono riportati i *template* dei prompt che hanno funzionato meglio con l'obiettivo dell'inferenza e che cercano di racchiudere la maggior parte dei suggerimenti sopra riportati.
"""

prompt_emotions_llama = """ You are an expert in emotion annotation from texts. Read the following text: "{texts}" and just assign a score from 0 to 1 (floating point number) for each of the emotions without giving any explanation. So this is what you have to do:
    1. Read the text
    2. Assign to the emotion a score from 0 to 1 (could be more than one emotion). At least 1 should be more than 0.
    The emotions to consider are described later. Respond with the scores for each emotion in the format contained in the block ###BEGIN and ###END.
    Only include in your answer the following format between ###BEGIN and ###END:
    ###BEGIN
    - Joy = *ASSIGN SCORE*
    - Love = *ASSIGN SCORE*
    - Anger = *ASSIGN SCORE*
    - Optimism = *ASSIGN SCORE*
    - Trust = *ASSIGN SCORE*
    - Sadness = *ASSIGN SCORE*
    - Disgust = *ASSIGN SCORE*
    - Pessimism = *ASSIGN SCORE*
    - Fear = *ASSIGN SCORE*
    - Anticipation = *ASSIGN SCORE*
    - Surprise = *ASSIGN SCORE*
    - Neutral = *ASSIGN SCORE*
    ###END"""

prompt_morality_llama = """ You are an expert in morality trait annotation from texts. Read the following text: "{texts}" and assign a score from 0 to 1 (floating point number) for each of the morality trait without giving any explanation. So this is what you have to do:
    1. Read the text
    2. Assign the score to the morality trait from 0 to 1 (could be more than one). At least 1 should be more than 0.
    The morality traits to consider are described later. Respond with the scores for each morality trait in the format contained in the block ###BEGIN and ###END.
    Only include in your answer the following format between ###BEGIN and ###END:
    ###BEGIN
    - Care = *ASSIGN SCORE*
    - Harm = *ASSIGN SCORE*
    - Fairness = *ASSIGN SCORE*
    - Cheating = *ASSIGN SCORE*
    - Loyalty = *ASSIGN SCORE*
    - Betrayal = *ASSIGN SCORE*
    - Authority = *ASSIGN SCORE*
    - Purity = *ASSIGN SCORE*
    - Subversion = *ASSIGN SCORE*
    - Degradation = *ASSIGN SCORE*
    - Neutral = *ASSIGN SCORE*
    ###END"""

"""## **Mistral**

Cercando modi per migliorare l'output del modello Mistral modificando il prompt viene suggerito di utilizzare dei token speciali quali `[INST]` a inizio del prompt e `[\INST]` a fine prompt. Questa tecnica orienta meglio il modello nella generazione dell'output richiesto dall'utente **[16]**.
"""

prompt_morality_mistral = """[INST] You are an expert in morality trait annotation from texts. Read the following text: "{texts}" and assign a score from 0 to 1 (floating point number) for each of the morality trait without giving any explanation. So this is what you have to do:
    1. Read the text
    2. Assign the score to the morality trait from 0 to 1 (could be more than one). At least 1 should be more than 0.
    The morality traits to consider are described later. Respond with the scores for each morality trait in the format contained in the block ###BEGIN and ###END.
    Only include in your answer the following format between ###BEGIN and ###END:
    ###BEGIN
    - Care = *ASSIGN SCORE*
    - Harm = *ASSIGN SCORE*
    - Fairness = *ASSIGN SCORE*
    - Cheating = *ASSIGN SCORE*
    - Loyalty = *ASSIGN SCORE*
    - Betrayal = *ASSIGN SCORE*
    - Authority = *ASSIGN SCORE*
    - Purity = *ASSIGN SCORE*
    - Subversion = *ASSIGN SCORE*
    - Degradation = *ASSIGN SCORE*
    ###END
    [\INST]"""

prompt_emotions_mistral = """[INST] You are an expert in emotion annotation from texts. Read the following text: "{texts}" and just assign a score from 0 to 1 (floating point number) for each of the emotions without giving any explanation. So this is what you have to do:
    1. Read the text
    2. Assign to the emotion a score from 0 to 1 (could be more than one emotion). At least 1 should be more than 0.
    The emotions to consider are described later. Respond with the scores for each emotion in the format contained in the block ###BEGIN and ###END.
    Only include in your answer the following format between ###BEGIN and ###END:
    ###BEGIN
    - Joy = *ASSIGN SCORE*
    - Love = *ASSIGN SCORE*
    - Anger = *ASSIGN SCORE*
    - Optimism = *ASSIGN SCORE*
    - Trust = *ASSIGN SCORE*
    - Sadness = *ASSIGN SCORE*
    - Disgust = *ASSIGN SCORE*
    - Pessimism = *ASSIGN SCORE*
    - Fear = *ASSIGN SCORE*
    - Anticipation = *ASSIGN SCORE*
    - Surprise = *ASSIGN SCORE*
    ###END
    [\INST]"""

"""## **Gemma**

Per migliorare invece l'output del modello Gemma 2 (ma in generale per la famiglia di modelli Gemma) il prompt va modificato specificando di chi è il "turno". Quindi a inizio prompt si deve specificare che è il turno dell'utente tramite `<start_of_turn>user`. A fine prompt, per indicare al modello che è il suo turno di esprimersi bisogna inserire: `<end_of_turn>
<start_of_turn>model` **[17]**.
"""

prompt_morality_gemma = """<start_of_turn>user
    You are an expert in morality trait annotation from texts. Read the following text: "{texts}" and assign a score from 0 to 1 (floating point number) for each of the morality trait without giving any explanation. You do not have to access any external source. So this is what you have to do:
    1. Read the text
    2. Assign the score to the morality trait from 0 to 1 (could be more than one). At least 1 should be more than 0.
    The morality traits to consider are described later. Respond with the scores for each morality trait in the format contained in the block ###BEGIN and ###END.
    Only include in your answer the following format between ###BEGIN and ###END:
    ###BEGIN
    - Care = *ASSIGN SCORE*
    - Harm = *ASSIGN SCORE*
    - Fairness = *ASSIGN SCORE*
    - Cheating = *ASSIGN SCORE*
    - Loyalty = *ASSIGN SCORE*
    - Betrayal = *ASSIGN SCORE*
    - Authority = *ASSIGN SCORE*
    - Purity = *ASSIGN SCORE*
    - Subversion = *ASSIGN SCORE*
    - Degradation = *ASSIGN SCORE*
    - Neutral = *ASSIGN SCORE*
    ###END
    <end_of_turn>
    <start_of_turn>model"""

prompt_emotions_gemma = """<start_of_turn>user
    You are an expert in emotion annotation from texts. Read the following text: "{texts}" and just assign a score from 0 to 1 (floating point number) for each of the emotions without giving any explanation. You do not have to access any external source. So this is what you have to do:
    1. Read the text
    2. Assign to the emotion a score from 0 to 1 (could be more than one emotion). At least 1 should be more than 0.
    The emotions to consider are described later. Respond with the scores for each emotion in the format contained in the block ###BEGIN and ###END.
    Only include in your answer the following format between ###BEGIN and ###END:
    ###BEGIN
    - Joy = *ASSIGN SCORE*
    - Love = *ASSIGN SCORE*
    - Anger = *ASSIGN SCORE*
    - Optimism = *ASSIGN SCORE*
    - Trust = *ASSIGN SCORE*
    - Sadness = *ASSIGN SCORE*
    - Disgust = *ASSIGN SCORE*
    - Pessimism = *ASSIGN SCORE*
    - Fear = *ASSIGN SCORE*
    - Anticipation = *ASSIGN SCORE*
    - Surprise = *ASSIGN SCORE*
    - Neutral = *ASSIGN SCORE*
    ###END
    <end_of_turn>
    <start_of_turn>model"""

"""# **References**

1. Greco, C. M., Zangari, L., Picca, D., & Tagarelli, A. (2024). *E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases.* arXiv preprint arXiv:2409.09001.URL: [https://arxiv.org/abs/2409.09001](https://arxiv.org/abs/2409.09001).

2. Lei, Y., Miah, M. M. M., Qamar, A., Reddy, S. R., Tong, J., Xu, H., & Huang, R. (2024). *EMONA: Event-level Moral Opinions in News Articles.* arXiv preprint arXiv:2404.01715. URL: [https://arxiv.org/abs/2404.01715](https://arxiv.org/abs/2404.01715)

3. Misra, Rishabh. *News Category Dataset.* arXiv preprint arXiv:2209.11429 (2022). URL: [https://arxiv.org/abs/2209.11429](https://arxiv.org/abs/2209.11429)

4. Misra, Rishabh and Jigyasa Grover. *Sculpting Data for ML: The first act of Machine Learning.* ISBN 9798585463570 (2021). URL: [https://www.researchgate.net/publication/348325375_Sculpting_Data_for_ML_The_first_act_of_Machine_Learning](https://www.researchgate.net/publication/348325375_Sculpting_Data_for_ML_The_first_act_of_Machine_Learning)

5. Team Meta. *Introducing Meta Llama 3: The Most Capable Openly Available LLM to Date.* AI at Meta, URL: [ai.meta.com/blog/meta-llama-3/](ai.meta.com/blog/meta-llama-3/).

6. Jingjing Xu, Wangchunshu Zhou, Zhiyi Fu, Hao Zhou, and Lei Li. *A survey on green deep learning*, Nov 2021. URL: [https://arxiv.org/abs/2111.05193](https://arxiv.org/abs/2111.05193).

7. Team Restack. *Llama 3.1 Tokenization Strategies.”*Restackio, URL: [www.restack.io/p/llama-3-1-answer-tokenization-strategies-cat-ai](www.restack.io/p/llama-3-1-answer-tokenization-strategies-cat-ai).

8. StatsTutor. *Spearman’s correlation*. URL: [https://www.statstutor.ac.uk/resources/uploaded/spearmans.pdf](https://www.statstutor.ac.uk/resources/uploaded/spearmans.pdf)

9. Kolmogorova, A. V., Kalinin, A. A., & Malikova, A. V. (2020). *The problem of retrieving neutral classes of texts in Russian in multiclass emotional text analysis*. In EUR Workshop Proceedings (Vol. 28522020). URL: [https://ceur-ws.org/Vol-2852/paper6.pdf](https://ceur-ws.org/Vol-2852/paper6.pdf)

10. Mistral AI. *Mistral*, [huggingface.co/docs/transformers/model_doc/mistral](huggingface.co/docs/transformers/model_doc/mistral).

11. Mistral AI. *“Tokenization.” Mistral AI Large Language Models*, [https://docs.mistral.ai/guides/tokenization/#:~:text=We%20first%20encode%20the%20input,embedding%20layer%20and%20transformer%20blocks.](https://docs.mistral.ai/guides/tokenization/#:~:text=We%20first%20encode%20the%20input,embedding%20layer%20and%20transformer%20blocks).

12. Google DeepMind. *“Google/Gemma-2-9b-It · Hugging Face.”* [https://huggingface.co/google/gemma-2-9b-it](https://huggingface.co/google/gemma-2-9b-it).

13. DeepMind, Gemma Team, Google, et al. *“Gemma 2: Improving Open Language Models at a Practical Size.”* [arxiv.org/html/2408.00118v1](arxiv.org/html/2408.00118v1).

14. Kernes, Jonathan. *“Sentencepiece Tokenizer Demystified.”* Medium, Towards Data Science, 5 June 2023, [towardsdatascience.com/sentencepiece-tokenizer-demystified-d0a3aac19b15](towardsdatascience.com/sentencepiece-tokenizer-demystified-d0a3aac19b15).

15. Team Meta. *Prompting: How-to Guides.* Llama 3.1, URL: [www.llama.com/docs/how-to-guides/prompting/](www.llama.com/docs/how-to-guides/prompting/).

16. Chambers, Mike. *“How to Prompt Mistral AI Models, and Why.”* Community.Aws, [community.aws/content/2dFNOnLVQRhyrOrMsloofnW0ckZ/how-to-prompt-mistral-ai-models-and-why](community.aws/content/2dFNOnLVQRhyrOrMsloofnW0ckZ/how-to-prompt-mistral-ai-models-and-why).

17. *“Gemma – Nextra.”* Prompt Engineering Guide, [www.promptingguide.ai/models/gemma](www.promptingguide.ai/models/gemma).
"""

